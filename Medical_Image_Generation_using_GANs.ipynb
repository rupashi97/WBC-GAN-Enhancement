{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qFRZ0wrfjqO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDg51WFkuRCD"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z85bB165fl_Y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-l8J1zGHhELX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set the path to the directory containing the images\n",
        "images_dir = \"/content/drive/My Drive/ECE 176/dataset-master/JPEGImages\"\n",
        "\n",
        "# Set the path to the CSV file containing the class labels\n",
        "labels_file = \"/content/drive/My Drive/ECE 176/dataset-master/bccd_labels.csv\"\n",
        "\n",
        "# Load the class labels from the CSV file into a pandas DataFrame\n",
        "labels_df = pd.read_csv(labels_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVfG2y29jr7T",
        "outputId": "26aa1d2b-e8b8-421e-e723-2c17c1b01dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Image number: 0 saved\n",
            "\n",
            "Image number: 1 saved\n",
            "\n",
            "Image number: 2 saved\n",
            "\n",
            "Image number: 3 saved\n",
            "\n",
            "Image number: 4 saved\n",
            "\n",
            "Image number: 5 saved\n",
            "\n",
            "Image number: 6 saved\n",
            "\n",
            "Image number: 7 saved\n",
            "\n",
            "Image number: 8 saved\n",
            "\n",
            "Image number: 9 saved\n",
            "\n",
            "Image number: 10 saved\n",
            "\n",
            "Image number: 10 saved\n",
            "\n",
            "Image number: 11 saved\n",
            "\n",
            "Image number: 12 saved\n",
            "\n",
            "Image number: 13 saved\n",
            "\n",
            "Image number: 14 saved\n",
            "\n",
            "Image number: 15 saved\n",
            "\n",
            "Image number: 16 saved\n",
            "\n",
            "Image number: 17 saved\n",
            "\n",
            "Image number: 18 saved\n",
            "\n",
            "Image number: 19 saved\n",
            "\n",
            "Image number: 20 saved\n",
            "\n",
            "Image number: 21 saved\n",
            "\n",
            "Image number: 22 saved\n",
            "\n",
            "Image number: 23 saved\n",
            "\n",
            "Image number: 24 saved\n",
            "\n",
            "Image number: 26 saved\n",
            "\n",
            "Image number: 28 saved\n",
            "\n",
            "Image number: 29 saved\n",
            "\n",
            "Image number: 30 saved\n",
            "\n",
            "Image number: 31 saved\n",
            "\n",
            "Image number: 31 saved\n",
            "\n",
            "Image number: 32 saved\n",
            "\n",
            "Image number: 33 saved\n",
            "\n",
            "Image number: 34 saved\n",
            "\n",
            "Image number: 34 saved\n",
            "\n",
            "Image number: 35 saved\n",
            "\n",
            "Image number: 36 saved\n",
            "\n",
            "Image number: 37 saved\n",
            "\n",
            "Image number: 38 saved\n",
            "\n",
            "Image number: 39 saved\n",
            "\n",
            "Image number: 40 saved\n",
            "\n",
            "Image number: 41 saved\n",
            "\n",
            "Image number: 42 saved\n",
            "\n",
            "Image number: 43 saved\n",
            "\n",
            "Image number: 43 saved\n",
            "\n",
            "Image number: 44 saved\n",
            "\n",
            "Image number: 44 saved\n",
            "\n",
            "Image number: 45 saved\n",
            "\n",
            "Image number: 46 saved\n",
            "\n",
            "Image number: 47 saved\n",
            "\n",
            "Image number: 48 saved\n",
            "\n",
            "Image number: 49 saved\n",
            "\n",
            "Image number: 50 saved\n",
            "\n",
            "Image number: 52 saved\n",
            "\n",
            "Image number: 53 saved\n",
            "\n",
            "Image number: 54 saved\n",
            "\n",
            "Image number: 55 saved\n",
            "\n",
            "Image number: 56 saved\n",
            "\n",
            "Image number: 57 saved\n",
            "\n",
            "Image number: 58 saved\n",
            "\n",
            "Image number: 59 saved\n",
            "\n",
            "Image number: 62 saved\n",
            "\n",
            "Image number: 63 saved\n",
            "\n",
            "Image number: 64 saved\n",
            "\n",
            "Image number: 65 saved\n",
            "\n",
            "Image number: 65 saved\n",
            "\n",
            "Image number: 66 saved\n",
            "\n",
            "Image number: 67 saved\n",
            "\n",
            "Image number: 68 saved\n",
            "\n",
            "Image number: 69 saved\n",
            "\n",
            "Image number: 70 saved\n",
            "\n",
            "Image number: 70 saved\n",
            "\n",
            "Image number: 71 saved\n",
            "\n",
            "Image number: 72 saved\n",
            "\n",
            "Image number: 73 saved\n",
            "\n",
            "Image number: 74 saved\n",
            "\n",
            "Image number: 75 saved\n",
            "\n",
            "Image number: 76 saved\n",
            "\n",
            "Image number: 77 saved\n",
            "\n",
            "Image number: 78 saved\n",
            "\n",
            "Image number: 79 saved\n",
            "\n",
            "Image number: 81 saved\n",
            "\n",
            "Image number: 82 saved\n",
            "\n",
            "Image number: 83 saved\n",
            "\n",
            "Image number: 86 saved\n",
            "\n",
            "Image number: 87 saved\n",
            "\n",
            "Image number: 88 saved\n",
            "\n",
            "Image number: 89 saved\n",
            "\n",
            "Image number: 90 saved\n",
            "\n",
            "Image number: 91 saved\n",
            "\n",
            "Image number: 92 saved\n",
            "\n",
            "Image number: 93 saved\n",
            "\n",
            "Image number: 94 saved\n",
            "\n",
            "Image number: 95 saved\n",
            "\n",
            "Image number: 96 saved\n",
            "\n",
            "Image number: 97 saved\n",
            "\n",
            "Image number: 98 saved\n",
            "\n",
            "Image number: 99 saved\n",
            "\n",
            "Image number: 100 saved\n",
            "\n",
            "Image number: 101 saved\n",
            "\n",
            "Image number: 103 saved\n",
            "\n",
            "Image number: 103 saved\n",
            "\n",
            "Image number: 104 saved\n",
            "\n",
            "Image number: 106 saved\n",
            "\n",
            "Image number: 107 saved\n",
            "\n",
            "Image number: 108 saved\n",
            "\n",
            "Image number: 109 saved\n",
            "\n",
            "Image number: 110 saved\n",
            "\n",
            "Image number: 111 saved\n",
            "\n",
            "Image number: 112 saved\n",
            "\n",
            "Image number: 113 saved\n",
            "\n",
            "Image number: 114 saved\n",
            "\n",
            "Image number: 115 saved\n",
            "\n",
            "Image number: 117 saved\n",
            "\n",
            "Image number: 120 saved\n",
            "\n",
            "Image number: 123 saved\n",
            "\n",
            "Image number: 124 saved\n",
            "\n",
            "Image number: 125 saved\n",
            "\n",
            "Image number: 126 saved\n",
            "\n",
            "Image number: 127 saved\n",
            "\n",
            "Image number: 130 saved\n",
            "\n",
            "Image number: 132 saved\n",
            "\n",
            "Image number: 133 saved\n",
            "\n",
            "Image number: 134 saved\n",
            "\n",
            "Image number: 135 saved\n",
            "\n",
            "Image number: 136 saved\n",
            "\n",
            "Image number: 137 saved\n",
            "\n",
            "Image number: 139 saved\n",
            "\n",
            "Image number: 140 saved\n",
            "\n",
            "Image number: 141 saved\n",
            "\n",
            "Image number: 142 saved\n",
            "\n",
            "Image number: 143 saved\n",
            "\n",
            "Image number: 144 saved\n",
            "\n",
            "Image number: 145 saved\n",
            "\n",
            "Image number: 147 saved\n",
            "\n",
            "Image number: 148 saved\n",
            "\n",
            "Image number: 149 saved\n",
            "\n",
            "Image number: 150 saved\n",
            "\n",
            "Image number: 152 saved\n",
            "\n",
            "Image number: 154 saved\n",
            "\n",
            "Image number: 156 saved\n",
            "\n",
            "Image number: 157 saved\n",
            "\n",
            "Image number: 158 saved\n",
            "\n",
            "Image number: 159 saved\n",
            "\n",
            "Image number: 160 saved\n",
            "\n",
            "Image number: 161 saved\n",
            "\n",
            "Image number: 162 saved\n",
            "\n",
            "Image number: 163 saved\n",
            "\n",
            "Image number: 164 saved\n",
            "\n",
            "Image number: 165 saved\n",
            "\n",
            "Image number: 166 saved\n",
            "\n",
            "Image number: 167 saved\n",
            "\n",
            "Image number: 168 saved\n",
            "\n",
            "Image number: 169 saved\n",
            "\n",
            "Image number: 170 saved\n",
            "\n",
            "Image number: 171 saved\n",
            "\n",
            "Image number: 172 saved\n",
            "\n",
            "Image number: 174 saved\n",
            "\n",
            "Image number: 175 saved\n",
            "\n",
            "Image number: 176 saved\n",
            "\n",
            "Image number: 176 saved\n",
            "\n",
            "Image number: 177 saved\n",
            "\n",
            "Image number: 178 saved\n",
            "\n",
            "Image number: 179 saved\n",
            "\n",
            "Image number: 180 saved\n",
            "\n",
            "Image number: 182 saved\n",
            "\n",
            "Image number: 183 saved\n",
            "\n",
            "Image number: 184 saved\n",
            "\n",
            "Image number: 187 saved\n",
            "\n",
            "Image number: 189 saved\n",
            "\n",
            "Image number: 190 saved\n",
            "\n",
            "Image number: 191 saved\n",
            "\n",
            "Image number: 192 saved\n",
            "\n",
            "Image number: 193 saved\n",
            "\n",
            "Image number: 193 saved\n",
            "\n",
            "Image number: 195 saved\n",
            "\n",
            "Image number: 195 saved\n",
            "\n",
            "Image number: 196 saved\n",
            "\n",
            "Image number: 197 saved\n",
            "\n",
            "Image number: 198 saved\n",
            "\n",
            "Image number: 199 saved\n",
            "\n",
            "Image number: 200 saved\n",
            "\n",
            "Image number: 201 saved\n",
            "\n",
            "Image number: 202 saved\n",
            "\n",
            "Image number: 203 saved\n",
            "\n",
            "Image number: 204 saved\n",
            "\n",
            "Image number: 205 saved\n",
            "\n",
            "Image number: 206 saved\n",
            "\n",
            "Image number: 207 saved\n",
            "\n",
            "Image number: 208 saved\n",
            "\n",
            "Image number: 209 saved\n",
            "\n",
            "Image number: 210 saved\n",
            "\n",
            "Image number: 211 saved\n",
            "\n",
            "Image number: 212 saved\n",
            "\n",
            "Image number: 214 saved\n",
            "\n",
            "Image number: 215 saved\n",
            "\n",
            "Image number: 216 saved\n",
            "\n",
            "Image number: 217 saved\n",
            "\n",
            "Image number: 218 saved\n",
            "\n",
            "Image number: 219 saved\n",
            "\n",
            "Image number: 220 saved\n",
            "\n",
            "Image number: 221 saved\n",
            "\n",
            "Image number: 222 saved\n",
            "\n",
            "Image number: 223 saved\n",
            "\n",
            "Image number: 224 saved\n",
            "\n",
            "Image number: 225 saved\n",
            "\n",
            "Image number: 226 saved\n",
            "\n",
            "Image number: 227 saved\n",
            "\n",
            "Image number: 228 saved\n",
            "\n",
            "Image number: 229 saved\n",
            "\n",
            "Image number: 230 saved\n",
            "\n",
            "Image number: 231 saved\n",
            "\n",
            "Image number: 232 saved\n",
            "\n",
            "Image number: 233 saved\n",
            "\n",
            "Image number: 234 saved\n",
            "\n",
            "Image number: 235 saved\n",
            "\n",
            "Image number: 236 saved\n",
            "\n",
            "Image number: 237 saved\n",
            "\n",
            "Image number: 239 saved\n",
            "\n",
            "Image number: 240 saved\n",
            "\n",
            "Image number: 241 saved\n",
            "\n",
            "Image number: 242 saved\n",
            "\n",
            "Image number: 242 saved\n",
            "\n",
            "Image number: 243 saved\n",
            "\n",
            "Image number: 244 saved\n",
            "\n",
            "Image number: 245 saved\n",
            "\n",
            "Image number: 246 saved\n",
            "\n",
            "Image number: 247 saved\n",
            "\n",
            "Image number: 248 saved\n",
            "\n",
            "Image number: 249 saved\n",
            "\n",
            "Image number: 249 saved\n",
            "\n",
            "Image number: 250 saved\n",
            "\n",
            "Image number: 251 saved\n",
            "\n",
            "Image number: 252 saved\n",
            "\n",
            "Image number: 253 saved\n",
            "\n",
            "Image number: 254 saved\n",
            "\n",
            "Image number: 255 saved\n",
            "\n",
            "Image number: 256 saved\n",
            "\n",
            "Image number: 257 saved\n",
            "\n",
            "Image number: 258 saved\n",
            "\n",
            "Image number: 259 saved\n",
            "\n",
            "Image number: 260 saved\n",
            "\n",
            "Image number: 261 saved\n",
            "\n",
            "Image number: 262 saved\n",
            "\n",
            "Image number: 263 saved\n",
            "\n",
            "Image number: 264 saved\n",
            "\n",
            "Image number: 265 saved\n",
            "\n",
            "Image number: 266 saved\n",
            "\n",
            "Image number: 267 saved\n",
            "\n",
            "Image number: 268 saved\n",
            "\n",
            "Image number: 269 saved\n",
            "\n",
            "Image number: 270 saved\n",
            "\n",
            "Image number: 271 saved\n",
            "\n",
            "Image number: 272 saved\n",
            "\n",
            "Image number: 273 saved\n",
            "\n",
            "Image number: 274 saved\n",
            "\n",
            "Image number: 275 saved\n",
            "\n",
            "Image number: 276 saved\n",
            "\n",
            "Image number: 277 saved\n",
            "\n",
            "Image number: 278 saved\n",
            "\n",
            "Image number: 279 saved\n",
            "\n",
            "Image number: 281 saved\n",
            "\n",
            "Image number: 282 saved\n",
            "\n",
            "Image number: 283 saved\n",
            "\n",
            "Image number: 284 saved\n",
            "\n",
            "Image number: 285 saved\n",
            "\n",
            "Image number: 287 saved\n",
            "\n",
            "Image number: 288 saved\n",
            "\n",
            "Image number: 289 saved\n",
            "\n",
            "Image number: 290 saved\n",
            "\n",
            "Image number: 291 saved\n",
            "\n",
            "Image number: 292 saved\n",
            "\n",
            "Image number: 293 saved\n",
            "\n",
            "Image number: 294 saved\n",
            "\n",
            "Image number: 295 saved\n",
            "\n",
            "Image number: 296 saved\n",
            "\n",
            "Image number: 297 saved\n",
            "\n",
            "Image number: 298 saved\n",
            "\n",
            "Image number: 299 saved\n",
            "\n",
            "Image number: 300 saved\n",
            "\n",
            "Image number: 301 saved\n",
            "\n",
            "Image number: 302 saved\n",
            "\n",
            "Image number: 303 saved\n",
            "\n",
            "Image number: 304 saved\n",
            "\n",
            "Image number: 305 saved\n",
            "\n",
            "Image number: 307 saved\n",
            "\n",
            "Image number: 308 saved\n",
            "\n",
            "Image number: 309 saved\n",
            "\n",
            "Image number: 310 saved\n",
            "\n",
            "Image number: 312 saved\n",
            "\n",
            "Image number: 313 saved\n",
            "\n",
            "Image number: 313 saved\n",
            "\n",
            "Image number: 314 saved\n",
            "\n",
            "Image number: 315 saved\n",
            "\n",
            "Image number: 317 saved\n",
            "\n",
            "Image number: 318 saved\n",
            "\n",
            "Image number: 319 saved\n",
            "\n",
            "Image number: 320 saved\n",
            "\n",
            "Image number: 322 saved\n",
            "\n",
            "Image number: 323 saved\n",
            "\n",
            "Image number: 324 saved\n",
            "\n",
            "Image number: 325 saved\n",
            "\n",
            "Image number: 326 saved\n",
            "\n",
            "Image number: 327 saved\n",
            "\n",
            "Image number: 329 saved\n",
            "\n",
            "Image number: 330 saved\n",
            "\n",
            "Image number: 331 saved\n",
            "\n",
            "Image number: 332 saved\n",
            "\n",
            "Image number: 333 saved\n",
            "\n",
            "Image number: 334 saved\n",
            "\n",
            "Image number: 335 saved\n",
            "\n",
            "Image number: 336 saved\n",
            "\n",
            "Image number: 337 saved\n",
            "\n",
            "Image number: 338 saved\n",
            "\n",
            "Image number: 339 saved\n",
            "\n",
            "Image number: 340 saved\n",
            "\n",
            "Image number: 341 saved\n",
            "\n",
            "Image number: 342 saved\n",
            "\n",
            "Image number: 343 saved\n",
            "\n",
            "Image number: 344 saved\n",
            "\n",
            "Image number: 345 saved\n",
            "\n",
            "Image number: 346 saved\n",
            "\n",
            "Image number: 347 saved\n",
            "\n",
            "Image number: 348 saved\n",
            "\n",
            "Image number: 349 saved\n",
            "\n",
            "Image number: 350 saved\n",
            "\n",
            "Image number: 351 saved\n",
            "\n",
            "Image number: 352 saved\n",
            "\n",
            "Image number: 353 saved\n",
            "\n",
            "Image number: 354 saved\n",
            "\n",
            "Image number: 355 saved\n",
            "\n",
            "Image number: 356 saved\n",
            "\n",
            "Image number: 357 saved\n",
            "\n",
            "Image number: 359 saved\n",
            "\n",
            "Image number: 360 saved\n",
            "\n",
            "Image number: 361 saved\n",
            "\n",
            "Image number: 362 saved\n",
            "\n",
            "Image number: 364 saved\n",
            "\n",
            "Image number: 365 saved\n",
            "\n",
            "Image number: 366 saved\n",
            "\n",
            "Image number: 367 saved\n",
            "\n",
            "Image number: 368 saved\n",
            "\n",
            "Image number: 369 saved\n",
            "\n",
            "Image number: 370 saved\n",
            "\n",
            "Image number: 371 saved\n",
            "\n",
            "Image number: 372 saved\n",
            "\n",
            "Image number: 374 saved\n",
            "\n",
            "Image number: 374 saved\n",
            "\n",
            "Image number: 375 saved\n",
            "\n",
            "Image number: 376 saved\n",
            "\n",
            "Image number: 377 saved\n",
            "\n",
            "Image number: 378 saved\n",
            "\n",
            "Image number: 379 saved\n",
            "\n",
            "Image number: 381 saved\n",
            "\n",
            "Image number: 382 saved\n",
            "\n",
            "Image number: 383 saved\n",
            "\n",
            "Image number: 384 saved\n",
            "\n",
            "Image number: 385 saved\n",
            "\n",
            "Image number: 386 saved\n",
            "\n",
            "Image number: 387 saved\n",
            "\n",
            "Image number: 388 saved\n",
            "\n",
            "Image number: 389 saved\n",
            "\n",
            "Image number: 390 saved\n",
            "\n",
            "Image number: 391 saved\n",
            "\n",
            "Image number: 392 saved\n",
            "\n",
            "Image number: 393 saved\n",
            "\n",
            "Image number: 395 saved\n",
            "\n",
            "Image number: 396 saved\n",
            "\n",
            "Image number: 397 saved\n",
            "\n",
            "Image number: 398 saved\n",
            "\n",
            "Image number: 400 saved\n",
            "\n",
            "Image number: 402 saved\n",
            "\n",
            "Image number: 403 saved\n",
            "\n",
            "Image number: 404 saved\n",
            "\n",
            "Image number: 405 saved\n",
            "\n",
            "Image number: 407 saved\n",
            "\n",
            "Image number: 408 saved\n",
            "\n",
            "Image number: 409 saved\n",
            "\n",
            "Image number: 410 saved\n"
          ]
        }
      ],
      "source": [
        "for i, row in labels_df.iterrows():\n",
        "\n",
        "    # Get the image number and class label for this row\n",
        "    image_number = row[\"Image\"]\n",
        "    class_labels = row[\"Category\"].split(\",\")  # Split the class labels by comma\n",
        "\n",
        "    if image_number<10:\n",
        "      filename = f\"BloodImage_0000{image_number}.jpg\"\n",
        "    elif image_number>9 and image_number <100:\n",
        "      filename = f\"BloodImage_000{image_number}.jpg\"\n",
        "    else:\n",
        "      filename = f\"BloodImage_00{image_number}.jpg\"\n",
        "    # Create the class folder if it doesn't exist\n",
        "    # Construct the image filename based on the image number\n",
        "    #filename = f\"BloodImage_{image_number}.jpg\"\n",
        "\n",
        "    # Loop through each class label for this image\n",
        "    for class_label in class_labels:\n",
        "        # Create the class folder if it doesn't exist\n",
        "        class_folder = os.path.join(images_dir, class_label.strip())  # Use strip() to remove whitespace\n",
        "        os.makedirs(class_folder, exist_ok=True)\n",
        "\n",
        "        # Move the image to the appropriate class folder\n",
        "        image_path = os.path.join(images_dir, filename)\n",
        "        destination_path = os.path.join(class_folder, filename)\n",
        "        shutil.copy(image_path, destination_path)\n",
        "        print('\\nImage number:', image_number,'saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paIXuNXooc12",
        "outputId": "7ba5ed17-10a9-4fbd-9d77-403355420df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEUTROPHIL: 215\n",
            "BASOPHIL: 4\n",
            "EOSINOPHIL: 94\n",
            "MONOCYTE: 23\n",
            "LYMPHOCYTE: 37\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Set the path to the directory containing the folders\n",
        "dir_path = \"/content/drive/My Drive/ECE 176/dataset-master/JPEGImages/classes\"\n",
        "\n",
        "# Loop through each folder in the directory\n",
        "for folder_name in os.listdir(dir_path):\n",
        "    folder_path = os.path.join(dir_path, folder_name)\n",
        "\n",
        "    # Check if this path is a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Count the number of files in this folder\n",
        "        file_count = len(os.listdir(folder_path))\n",
        "\n",
        "        # Print the folder name and file count\n",
        "        print(f\"{folder_name}: {file_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8d7r8X5oj5Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Set the directory of your dataset\n",
        "data_dir = '/content/drive/My Drive/ECE 176/dataset-master/JPEGImages/classes/LYMPHOCYTE'\n",
        "\n",
        "def load_images():\n",
        "    images = []\n",
        "    for filename in os.listdir(data_dir):\n",
        "        img = Image.open(os.path.join(data_dir, filename))\n",
        "        img = img.convert('RGB') # Convert to RGB format\n",
        "        img = img.resize((256, 256)) # Resize the image\n",
        "        img = np.asarray(img)\n",
        "        images.append(img)\n",
        "    return np.asarray(images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5Fudaf1osyy"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, BatchNormalization, LeakyReLU, UpSampling2D, Activation\n",
        "\n",
        "# Define the generator architecture\n",
        "def build_generator(latent_dim, img_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128 * int(img_shape[0] / 4) * int(img_shape[1] / 4), activation=\"relu\", input_dim=latent_dim))\n",
        "    model.add(Reshape((int(img_shape[0] / 4), int(img_shape[1] / 4), 128)))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(img_shape[2], kernel_size=3, padding='same'))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPFNDpptovVu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, Flatten, Dropout, ZeroPadding2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "def build_discriminator(img_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), strides=(2, 2), padding='same', input_shape=img_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rswNgBTuo3Q0"
      },
      "outputs": [],
      "source": [
        "# Define the loss functions\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Define the optimizer\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCg2gDvyo73L"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the training loop\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    # Generate random noise for the generator\n",
        "    noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Generate fake images using the generator\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        # Feed both real and fake images to the discriminator\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        # Calculate the loss for both the generator and discriminator\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # Calculate the gradients and apply them to the generator and discriminator\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "# Define the training function\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for batch in dataset:\n",
        "            gen_loss, disc_loss = train_step(batch)\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OQezFY-pDZw"
      },
      "outputs": [],
      "source": [
        "# Set the hyperparameters\n",
        "BATCH_SIZE = 32\n",
        "LATENT_DIM = 100\n",
        "EPOCHS = 700\n",
        "img_shape = (256, 256, 3)\n",
        "#discriminator = build_discriminator(img_shape)\n",
        "# Load the dataset\n",
        "images = load_images()\n",
        "\n",
        "# Preprocess the images\n",
        "images = (images.astype('float32') - 127.5) / 127.5\n",
        "dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(len(images)).batch(BATCH_SIZE)\n",
        "\n",
        "# Build the generator and discriminator\n",
        "generator = build_generator(LATENT_DIM, img_shape)\n",
        "discriminator = build_discriminator(img_shape)\n",
        "\n",
        "# Define the loss functions\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Define the optimizer\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb18GwqjriXK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generator_loss(fake_output):\n",
        "    return tf.reduce_mean(tf.keras.losses.binary_crossentropy(tf.ones_like(fake_output), fake_output))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VF0rKzZrjNr"
      },
      "outputs": [],
      "source": [
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tyBDYaRpM5W",
        "outputId": "3cd78c56-09cc-43b6-cc63-6615231b0442"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5676: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Generator Loss: 1.8427708148956299, Discriminator Loss: 2.855480909347534\n",
            "Epoch 2, Generator Loss: 1.6252357959747314, Discriminator Loss: 1.6725385189056396\n",
            "Epoch 3, Generator Loss: 1.9210349321365356, Discriminator Loss: 0.7116492986679077\n",
            "Epoch 4, Generator Loss: 0.9707484245300293, Discriminator Loss: 1.292386531829834\n",
            "Epoch 5, Generator Loss: 1.2345104217529297, Discriminator Loss: 1.146935224533081\n",
            "Epoch 6, Generator Loss: 1.4004091024398804, Discriminator Loss: 0.9380661845207214\n",
            "Epoch 7, Generator Loss: 1.733908772468567, Discriminator Loss: 1.790191650390625\n",
            "Epoch 8, Generator Loss: 1.1381916999816895, Discriminator Loss: 1.467679738998413\n",
            "Epoch 9, Generator Loss: 0.39941126108169556, Discriminator Loss: 2.1669516563415527\n",
            "Epoch 10, Generator Loss: 1.3694658279418945, Discriminator Loss: 1.6364755630493164\n",
            "Epoch 11, Generator Loss: 1.282177448272705, Discriminator Loss: 2.653398275375366\n",
            "Epoch 12, Generator Loss: 2.123133659362793, Discriminator Loss: 0.659996747970581\n",
            "Epoch 13, Generator Loss: 2.094503402709961, Discriminator Loss: 1.3747937679290771\n",
            "Epoch 14, Generator Loss: 1.1319704055786133, Discriminator Loss: 1.4294781684875488\n",
            "Epoch 15, Generator Loss: 0.4467368721961975, Discriminator Loss: 6.892098426818848\n",
            "Epoch 16, Generator Loss: 5.567574501037598, Discriminator Loss: 0.12447464466094971\n",
            "Epoch 17, Generator Loss: 8.22877025604248, Discriminator Loss: 5.468538284301758\n",
            "Epoch 18, Generator Loss: 5.223582744598389, Discriminator Loss: 0.03296243026852608\n",
            "Epoch 19, Generator Loss: 1.7654850482940674, Discriminator Loss: 2.068096876144409\n",
            "Epoch 20, Generator Loss: 2.814957618713379, Discriminator Loss: 7.383275032043457\n",
            "Epoch 21, Generator Loss: 9.595709800720215, Discriminator Loss: 0.041775837540626526\n",
            "Epoch 22, Generator Loss: 1.969179391860962, Discriminator Loss: 1.2362653017044067\n",
            "Epoch 23, Generator Loss: 14.411625862121582, Discriminator Loss: 3.272853136062622\n",
            "Epoch 24, Generator Loss: 3.0289950370788574, Discriminator Loss: 0.6541963815689087\n",
            "Epoch 25, Generator Loss: 4.433484077453613, Discriminator Loss: 0.23028258979320526\n",
            "Epoch 26, Generator Loss: 3.546858310699463, Discriminator Loss: 0.4162583351135254\n",
            "Epoch 27, Generator Loss: 0.7473804950714111, Discriminator Loss: 2.930694580078125\n",
            "Epoch 28, Generator Loss: 2.250040292739868, Discriminator Loss: 0.8010826110839844\n",
            "Epoch 29, Generator Loss: 1.758289098739624, Discriminator Loss: 1.6878474950790405\n",
            "Epoch 30, Generator Loss: 1.5835435390472412, Discriminator Loss: 1.1548552513122559\n",
            "Epoch 31, Generator Loss: 3.979597330093384, Discriminator Loss: 0.8193074464797974\n",
            "Epoch 32, Generator Loss: 4.263775825500488, Discriminator Loss: 0.49675485491752625\n",
            "Epoch 33, Generator Loss: 3.644296646118164, Discriminator Loss: 0.43750911951065063\n",
            "Epoch 34, Generator Loss: 2.4303600788116455, Discriminator Loss: 0.8244189023971558\n",
            "Epoch 35, Generator Loss: 2.863673210144043, Discriminator Loss: 0.34076744318008423\n",
            "Epoch 36, Generator Loss: 2.1377220153808594, Discriminator Loss: 0.4481317400932312\n",
            "Epoch 37, Generator Loss: 2.641033172607422, Discriminator Loss: 0.501578152179718\n",
            "Epoch 38, Generator Loss: 4.065548896789551, Discriminator Loss: 0.5198832154273987\n",
            "Epoch 39, Generator Loss: 1.5439763069152832, Discriminator Loss: 1.1579456329345703\n",
            "Epoch 40, Generator Loss: 3.5079503059387207, Discriminator Loss: 0.486142098903656\n",
            "Epoch 41, Generator Loss: 2.6549341678619385, Discriminator Loss: 0.9210118055343628\n",
            "Epoch 42, Generator Loss: 3.7326488494873047, Discriminator Loss: 0.24421679973602295\n",
            "Epoch 43, Generator Loss: 1.0167527198791504, Discriminator Loss: 1.1553947925567627\n",
            "Epoch 44, Generator Loss: 5.461572647094727, Discriminator Loss: 0.5858137011528015\n",
            "Epoch 45, Generator Loss: 1.8219876289367676, Discriminator Loss: 1.0893423557281494\n",
            "Epoch 46, Generator Loss: 1.7479496002197266, Discriminator Loss: 0.7338722944259644\n",
            "Epoch 47, Generator Loss: 3.421966552734375, Discriminator Loss: 0.18013308942317963\n",
            "Epoch 48, Generator Loss: 2.926612377166748, Discriminator Loss: 0.32242268323898315\n",
            "Epoch 49, Generator Loss: 2.562267303466797, Discriminator Loss: 0.7137447595596313\n",
            "Epoch 50, Generator Loss: 1.2715716361999512, Discriminator Loss: 2.3255443572998047\n",
            "Epoch 51, Generator Loss: 4.814105987548828, Discriminator Loss: 0.7707696557044983\n",
            "Epoch 52, Generator Loss: 1.011340856552124, Discriminator Loss: 2.6155683994293213\n",
            "Epoch 53, Generator Loss: 0.7910938858985901, Discriminator Loss: 4.454457759857178\n",
            "Epoch 54, Generator Loss: 6.22713565826416, Discriminator Loss: 1.9760268926620483\n",
            "Epoch 55, Generator Loss: 3.993168354034424, Discriminator Loss: 0.9884934425354004\n",
            "Epoch 56, Generator Loss: 0.15597766637802124, Discriminator Loss: 5.311145782470703\n",
            "Epoch 57, Generator Loss: 5.809870719909668, Discriminator Loss: 4.830532073974609\n",
            "Epoch 58, Generator Loss: 2.365482807159424, Discriminator Loss: 2.33562970161438\n",
            "Epoch 59, Generator Loss: 2.2315499782562256, Discriminator Loss: 2.334406852722168\n",
            "Epoch 60, Generator Loss: 1.2640841007232666, Discriminator Loss: 3.0752851963043213\n",
            "Epoch 61, Generator Loss: 0.516970157623291, Discriminator Loss: 2.7175111770629883\n",
            "Epoch 62, Generator Loss: 1.5294239521026611, Discriminator Loss: 3.9981751441955566\n",
            "Epoch 63, Generator Loss: 2.3316073417663574, Discriminator Loss: 1.9193443059921265\n",
            "Epoch 64, Generator Loss: 3.6790685653686523, Discriminator Loss: 0.24122780561447144\n",
            "Epoch 65, Generator Loss: 3.136376142501831, Discriminator Loss: 0.7507258653640747\n",
            "Epoch 66, Generator Loss: 4.1890130043029785, Discriminator Loss: 0.6229315996170044\n",
            "Epoch 67, Generator Loss: 3.525999069213867, Discriminator Loss: 1.0702208280563354\n",
            "Epoch 68, Generator Loss: 1.3825855255126953, Discriminator Loss: 2.117962121963501\n",
            "Epoch 69, Generator Loss: 3.6244266033172607, Discriminator Loss: 1.3996500968933105\n",
            "Epoch 70, Generator Loss: 6.646100997924805, Discriminator Loss: 0.1400279998779297\n",
            "Epoch 71, Generator Loss: 9.43304443359375, Discriminator Loss: 0.3225295841693878\n",
            "Epoch 72, Generator Loss: 8.085875511169434, Discriminator Loss: 1.1837602853775024\n",
            "Epoch 73, Generator Loss: 4.963693618774414, Discriminator Loss: 2.116647481918335\n",
            "Epoch 74, Generator Loss: 2.3560733795166016, Discriminator Loss: 2.8895745277404785\n",
            "Epoch 75, Generator Loss: 2.105539083480835, Discriminator Loss: 1.7647156715393066\n",
            "Epoch 76, Generator Loss: 3.215865135192871, Discriminator Loss: 0.8782254457473755\n",
            "Epoch 77, Generator Loss: 11.252723693847656, Discriminator Loss: 0.5876865386962891\n",
            "Epoch 78, Generator Loss: 7.23198127746582, Discriminator Loss: 1.4640897512435913\n",
            "Epoch 79, Generator Loss: 3.2448973655700684, Discriminator Loss: 1.8463380336761475\n",
            "Epoch 80, Generator Loss: 5.398597717285156, Discriminator Loss: 2.6102538108825684\n",
            "Epoch 81, Generator Loss: 3.283583641052246, Discriminator Loss: 2.4488978385925293\n",
            "Epoch 82, Generator Loss: 2.5991392135620117, Discriminator Loss: 3.2427406311035156\n",
            "Epoch 83, Generator Loss: 4.460463523864746, Discriminator Loss: 3.5328657627105713\n",
            "Epoch 84, Generator Loss: 3.4910218715667725, Discriminator Loss: 2.7664971351623535\n",
            "Epoch 85, Generator Loss: 3.27286434173584, Discriminator Loss: 1.0933183431625366\n",
            "Epoch 86, Generator Loss: 5.830904006958008, Discriminator Loss: 0.8941513299942017\n",
            "Epoch 87, Generator Loss: 4.0220746994018555, Discriminator Loss: 2.8159284591674805\n",
            "Epoch 88, Generator Loss: 2.828622817993164, Discriminator Loss: 3.457266330718994\n",
            "Epoch 89, Generator Loss: 1.288406491279602, Discriminator Loss: 3.4303650856018066\n",
            "Epoch 90, Generator Loss: 1.4657331705093384, Discriminator Loss: 3.2329702377319336\n",
            "Epoch 91, Generator Loss: 11.136960983276367, Discriminator Loss: 2.0092661380767822\n",
            "Epoch 92, Generator Loss: 7.5518479347229, Discriminator Loss: 0.4638701379299164\n",
            "Epoch 93, Generator Loss: 3.1008148193359375, Discriminator Loss: 1.3997198343276978\n",
            "Epoch 94, Generator Loss: 5.133923053741455, Discriminator Loss: 1.2471001148223877\n",
            "Epoch 95, Generator Loss: 7.591895580291748, Discriminator Loss: 0.9336046576499939\n",
            "Epoch 96, Generator Loss: 6.586759090423584, Discriminator Loss: 1.7471448183059692\n",
            "Epoch 97, Generator Loss: 4.09262752532959, Discriminator Loss: 1.4369995594024658\n",
            "Epoch 98, Generator Loss: 4.100711822509766, Discriminator Loss: 1.2059788703918457\n",
            "Epoch 99, Generator Loss: 4.200159549713135, Discriminator Loss: 0.961603045463562\n",
            "Epoch 100, Generator Loss: 6.2522478103637695, Discriminator Loss: 0.8668384552001953\n",
            "Epoch 101, Generator Loss: 8.341609001159668, Discriminator Loss: 1.5040428638458252\n",
            "Epoch 102, Generator Loss: 6.18651008605957, Discriminator Loss: 2.4613776206970215\n",
            "Epoch 103, Generator Loss: 3.0629353523254395, Discriminator Loss: 5.0724101066589355\n",
            "Epoch 104, Generator Loss: 1.1602811813354492, Discriminator Loss: 1.7875885963439941\n",
            "Epoch 105, Generator Loss: 5.841632843017578, Discriminator Loss: 0.5176497101783752\n",
            "Epoch 106, Generator Loss: 7.722564220428467, Discriminator Loss: 0.5897055268287659\n",
            "Epoch 107, Generator Loss: 5.22898006439209, Discriminator Loss: 1.3881915807724\n",
            "Epoch 108, Generator Loss: 4.966834545135498, Discriminator Loss: 0.5397214293479919\n",
            "Epoch 109, Generator Loss: 8.2381591796875, Discriminator Loss: 0.04149181395769119\n",
            "Epoch 110, Generator Loss: 13.001062393188477, Discriminator Loss: 0.38136595487594604\n",
            "Epoch 111, Generator Loss: 11.585559844970703, Discriminator Loss: 1.3356484174728394\n",
            "Epoch 112, Generator Loss: 11.24153995513916, Discriminator Loss: 2.3401095867156982\n",
            "Epoch 113, Generator Loss: 13.06570053100586, Discriminator Loss: 1.4568102359771729\n",
            "Epoch 114, Generator Loss: 5.142492294311523, Discriminator Loss: 1.5180561542510986\n",
            "Epoch 115, Generator Loss: 10.852029800415039, Discriminator Loss: 0.7010511159896851\n",
            "Epoch 116, Generator Loss: 10.552465438842773, Discriminator Loss: 1.6597956418991089\n",
            "Epoch 117, Generator Loss: 9.66415023803711, Discriminator Loss: 0.9441646337509155\n",
            "Epoch 118, Generator Loss: 6.914886474609375, Discriminator Loss: 0.2874334752559662\n",
            "Epoch 119, Generator Loss: 4.543942451477051, Discriminator Loss: 0.30877968668937683\n",
            "Epoch 120, Generator Loss: 6.112757205963135, Discriminator Loss: 0.5240395069122314\n",
            "Epoch 121, Generator Loss: 7.494641304016113, Discriminator Loss: 0.5865519642829895\n",
            "Epoch 122, Generator Loss: 6.160152435302734, Discriminator Loss: 0.3497176468372345\n",
            "Epoch 123, Generator Loss: 6.540574073791504, Discriminator Loss: 0.4834374785423279\n",
            "Epoch 124, Generator Loss: 6.830186367034912, Discriminator Loss: 0.2700881063938141\n",
            "Epoch 125, Generator Loss: 8.123437881469727, Discriminator Loss: 0.7143837213516235\n",
            "Epoch 126, Generator Loss: 8.499917984008789, Discriminator Loss: 0.45634713768959045\n",
            "Epoch 127, Generator Loss: 6.594696998596191, Discriminator Loss: 0.9563283324241638\n",
            "Epoch 128, Generator Loss: 3.872403383255005, Discriminator Loss: 1.1639353036880493\n",
            "Epoch 129, Generator Loss: 6.0505781173706055, Discriminator Loss: 0.8413249254226685\n",
            "Epoch 130, Generator Loss: 9.14735221862793, Discriminator Loss: 0.6144574880599976\n",
            "Epoch 131, Generator Loss: 6.955996513366699, Discriminator Loss: 0.8983305096626282\n",
            "Epoch 132, Generator Loss: 5.3403425216674805, Discriminator Loss: 0.8234429359436035\n",
            "Epoch 133, Generator Loss: 3.7592830657958984, Discriminator Loss: 0.8248690962791443\n",
            "Epoch 134, Generator Loss: 4.023530006408691, Discriminator Loss: 0.735946536064148\n",
            "Epoch 135, Generator Loss: 4.372403144836426, Discriminator Loss: 3.145425319671631\n",
            "Epoch 136, Generator Loss: 5.806583404541016, Discriminator Loss: 1.762385606765747\n",
            "Epoch 137, Generator Loss: 5.313704013824463, Discriminator Loss: 0.8308542966842651\n",
            "Epoch 138, Generator Loss: 3.014376163482666, Discriminator Loss: 0.9009935855865479\n",
            "Epoch 139, Generator Loss: 5.514081001281738, Discriminator Loss: 1.1714749336242676\n",
            "Epoch 140, Generator Loss: 3.935575485229492, Discriminator Loss: 1.0308799743652344\n",
            "Epoch 141, Generator Loss: 4.761743068695068, Discriminator Loss: 1.0147203207015991\n",
            "Epoch 142, Generator Loss: 6.804387092590332, Discriminator Loss: 2.1883580684661865\n",
            "Epoch 143, Generator Loss: 6.582216739654541, Discriminator Loss: 1.0907857418060303\n",
            "Epoch 144, Generator Loss: 2.531400203704834, Discriminator Loss: 1.6975913047790527\n",
            "Epoch 145, Generator Loss: 4.424261569976807, Discriminator Loss: 1.2422783374786377\n",
            "Epoch 146, Generator Loss: 4.361215114593506, Discriminator Loss: 0.820776641368866\n",
            "Epoch 147, Generator Loss: 3.08416748046875, Discriminator Loss: 1.5253766775131226\n",
            "Epoch 148, Generator Loss: 3.5380303859710693, Discriminator Loss: 0.6864211559295654\n",
            "Epoch 149, Generator Loss: 11.085662841796875, Discriminator Loss: 0.04886370152235031\n",
            "Epoch 150, Generator Loss: 14.351606369018555, Discriminator Loss: 0.18235504627227783\n",
            "Epoch 151, Generator Loss: 11.921059608459473, Discriminator Loss: 1.6728248596191406\n",
            "Epoch 152, Generator Loss: 8.216723442077637, Discriminator Loss: 0.5040897727012634\n",
            "Epoch 153, Generator Loss: 5.740963459014893, Discriminator Loss: 0.1953263133764267\n",
            "Epoch 154, Generator Loss: 5.734940052032471, Discriminator Loss: 0.7259701490402222\n",
            "Epoch 155, Generator Loss: 6.084436893463135, Discriminator Loss: 0.489280641078949\n",
            "Epoch 156, Generator Loss: 5.117079734802246, Discriminator Loss: 0.7892981171607971\n",
            "Epoch 157, Generator Loss: 10.4519681930542, Discriminator Loss: 2.267387628555298\n",
            "Epoch 158, Generator Loss: 15.327925682067871, Discriminator Loss: 2.3991825580596924\n",
            "Epoch 159, Generator Loss: 12.241277694702148, Discriminator Loss: 0.11524484306573868\n",
            "Epoch 160, Generator Loss: 2.995899200439453, Discriminator Loss: 1.0946975946426392\n",
            "Epoch 161, Generator Loss: 3.7890686988830566, Discriminator Loss: 2.783128499984741\n",
            "Epoch 162, Generator Loss: 4.170808792114258, Discriminator Loss: 1.0900177955627441\n",
            "Epoch 163, Generator Loss: 6.632306098937988, Discriminator Loss: 0.18020235002040863\n",
            "Epoch 164, Generator Loss: 9.481887817382812, Discriminator Loss: 0.748429000377655\n",
            "Epoch 165, Generator Loss: 7.664144515991211, Discriminator Loss: 0.2648264467716217\n",
            "Epoch 166, Generator Loss: 4.803335189819336, Discriminator Loss: 1.1380085945129395\n",
            "Epoch 167, Generator Loss: 3.093437671661377, Discriminator Loss: 1.2004528045654297\n",
            "Epoch 168, Generator Loss: 6.390030384063721, Discriminator Loss: 1.0333049297332764\n",
            "Epoch 169, Generator Loss: 4.509553909301758, Discriminator Loss: 1.7817209959030151\n",
            "Epoch 170, Generator Loss: 6.568816661834717, Discriminator Loss: 1.7764525413513184\n",
            "Epoch 171, Generator Loss: 7.255244731903076, Discriminator Loss: 0.16551512479782104\n",
            "Epoch 172, Generator Loss: 13.417703628540039, Discriminator Loss: 0.3728942275047302\n",
            "Epoch 173, Generator Loss: 6.9019694328308105, Discriminator Loss: 2.6670124530792236\n",
            "Epoch 174, Generator Loss: 6.412606716156006, Discriminator Loss: 1.1348876953125\n",
            "Epoch 175, Generator Loss: 8.891437530517578, Discriminator Loss: 0.2317037284374237\n",
            "Epoch 176, Generator Loss: 3.9154696464538574, Discriminator Loss: 1.514838457107544\n",
            "Epoch 177, Generator Loss: 3.2204971313476562, Discriminator Loss: 1.0940476655960083\n",
            "Epoch 178, Generator Loss: 2.4754562377929688, Discriminator Loss: 1.445317029953003\n",
            "Epoch 179, Generator Loss: 4.186680793762207, Discriminator Loss: 0.6152744293212891\n",
            "Epoch 180, Generator Loss: 5.899510383605957, Discriminator Loss: 0.12954047322273254\n",
            "Epoch 181, Generator Loss: 5.482352256774902, Discriminator Loss: 0.23759900033473969\n",
            "Epoch 182, Generator Loss: 7.973088264465332, Discriminator Loss: 0.4604080319404602\n",
            "Epoch 183, Generator Loss: 5.018491268157959, Discriminator Loss: 0.33514243364334106\n",
            "Epoch 184, Generator Loss: 2.4140939712524414, Discriminator Loss: 1.3675974607467651\n",
            "Epoch 185, Generator Loss: 2.762655258178711, Discriminator Loss: 0.7852746844291687\n",
            "Epoch 186, Generator Loss: 6.3107428550720215, Discriminator Loss: 0.4480195939540863\n",
            "Epoch 187, Generator Loss: 8.558389663696289, Discriminator Loss: 0.6492097973823547\n",
            "Epoch 188, Generator Loss: 9.453697204589844, Discriminator Loss: 0.684967577457428\n",
            "Epoch 189, Generator Loss: 8.77210807800293, Discriminator Loss: 0.6748108267784119\n",
            "Epoch 190, Generator Loss: 6.732789993286133, Discriminator Loss: 0.28999677300453186\n",
            "Epoch 191, Generator Loss: 8.469186782836914, Discriminator Loss: 0.8049770593643188\n",
            "Epoch 192, Generator Loss: 10.447023391723633, Discriminator Loss: 1.7611768245697021\n",
            "Epoch 193, Generator Loss: 10.75804328918457, Discriminator Loss: 1.536582350730896\n",
            "Epoch 194, Generator Loss: 7.392229080200195, Discriminator Loss: 1.000393033027649\n",
            "Epoch 195, Generator Loss: 6.079804420471191, Discriminator Loss: 2.1442253589630127\n",
            "Epoch 196, Generator Loss: 8.8291015625, Discriminator Loss: 0.8836487531661987\n",
            "Epoch 197, Generator Loss: 8.105565071105957, Discriminator Loss: 0.3723527789115906\n",
            "Epoch 198, Generator Loss: 3.541837692260742, Discriminator Loss: 0.9288181066513062\n",
            "Epoch 199, Generator Loss: 6.459013938903809, Discriminator Loss: 0.9604299664497375\n",
            "Epoch 200, Generator Loss: 4.416345596313477, Discriminator Loss: 1.0794442892074585\n",
            "Epoch 201, Generator Loss: 5.388097763061523, Discriminator Loss: 2.405503034591675\n",
            "Epoch 202, Generator Loss: 3.500154733657837, Discriminator Loss: 0.475364089012146\n",
            "Epoch 203, Generator Loss: 5.0381269454956055, Discriminator Loss: 0.46895551681518555\n",
            "Epoch 204, Generator Loss: 6.239147186279297, Discriminator Loss: 0.6834402084350586\n",
            "Epoch 205, Generator Loss: 3.9434165954589844, Discriminator Loss: 0.8940315842628479\n",
            "Epoch 206, Generator Loss: 2.6102919578552246, Discriminator Loss: 1.7157745361328125\n",
            "Epoch 207, Generator Loss: 5.24026346206665, Discriminator Loss: 0.36296579241752625\n",
            "Epoch 208, Generator Loss: 2.9289798736572266, Discriminator Loss: 0.5197614431381226\n",
            "Epoch 209, Generator Loss: 3.158311367034912, Discriminator Loss: 0.7366139888763428\n",
            "Epoch 210, Generator Loss: 4.314650535583496, Discriminator Loss: 0.7503715753555298\n",
            "Epoch 211, Generator Loss: 5.054691791534424, Discriminator Loss: 0.26227569580078125\n",
            "Epoch 212, Generator Loss: 4.060459613800049, Discriminator Loss: 0.37314265966415405\n",
            "Epoch 213, Generator Loss: 2.534963607788086, Discriminator Loss: 1.3581016063690186\n",
            "Epoch 214, Generator Loss: 3.3703463077545166, Discriminator Loss: 0.6546005606651306\n",
            "Epoch 215, Generator Loss: 6.884169578552246, Discriminator Loss: 0.15825064480304718\n",
            "Epoch 216, Generator Loss: 4.356613636016846, Discriminator Loss: 0.21401293575763702\n",
            "Epoch 217, Generator Loss: 5.119428634643555, Discriminator Loss: 0.3173252046108246\n",
            "Epoch 218, Generator Loss: 4.198902606964111, Discriminator Loss: 0.4562848210334778\n",
            "Epoch 219, Generator Loss: 5.365791320800781, Discriminator Loss: 1.2567262649536133\n",
            "Epoch 220, Generator Loss: 8.31235408782959, Discriminator Loss: 1.796405553817749\n",
            "Epoch 221, Generator Loss: 9.800348281860352, Discriminator Loss: 4.88995361328125\n",
            "Epoch 222, Generator Loss: 9.53060245513916, Discriminator Loss: 1.7897975444793701\n",
            "Epoch 223, Generator Loss: 6.215418815612793, Discriminator Loss: 0.6145132780075073\n",
            "Epoch 224, Generator Loss: 6.196208953857422, Discriminator Loss: 0.20982693135738373\n",
            "Epoch 225, Generator Loss: 3.1889193058013916, Discriminator Loss: 1.535660982131958\n",
            "Epoch 226, Generator Loss: 3.434274435043335, Discriminator Loss: 0.9160767793655396\n",
            "Epoch 227, Generator Loss: 5.404570579528809, Discriminator Loss: 0.7753373384475708\n",
            "Epoch 228, Generator Loss: 3.57368803024292, Discriminator Loss: 0.7844285368919373\n",
            "Epoch 229, Generator Loss: 4.264142990112305, Discriminator Loss: 0.2827017605304718\n",
            "Epoch 230, Generator Loss: 6.517858505249023, Discriminator Loss: 0.9377279877662659\n",
            "Epoch 231, Generator Loss: 8.980058670043945, Discriminator Loss: 0.35135209560394287\n",
            "Epoch 232, Generator Loss: 8.646310806274414, Discriminator Loss: 0.4803377091884613\n",
            "Epoch 233, Generator Loss: 9.144155502319336, Discriminator Loss: 0.43326103687286377\n",
            "Epoch 234, Generator Loss: 7.045928955078125, Discriminator Loss: 0.3823734521865845\n",
            "Epoch 235, Generator Loss: 8.372854232788086, Discriminator Loss: 1.0557719469070435\n",
            "Epoch 236, Generator Loss: 4.619373321533203, Discriminator Loss: 0.8134380578994751\n",
            "Epoch 237, Generator Loss: 5.777585983276367, Discriminator Loss: 0.3087068498134613\n",
            "Epoch 238, Generator Loss: 6.243648052215576, Discriminator Loss: 0.581694483757019\n",
            "Epoch 239, Generator Loss: 5.20949125289917, Discriminator Loss: 0.5789881944656372\n",
            "Epoch 240, Generator Loss: 5.814507484436035, Discriminator Loss: 0.201765775680542\n",
            "Epoch 241, Generator Loss: 3.989278554916382, Discriminator Loss: 0.26978105306625366\n",
            "Epoch 242, Generator Loss: 7.183638095855713, Discriminator Loss: 0.5805956721305847\n",
            "Epoch 243, Generator Loss: 4.885863304138184, Discriminator Loss: 0.6659584045410156\n",
            "Epoch 244, Generator Loss: 5.898494720458984, Discriminator Loss: 1.064326524734497\n",
            "Epoch 245, Generator Loss: 5.336319446563721, Discriminator Loss: 1.3765325546264648\n",
            "Epoch 246, Generator Loss: 7.584562301635742, Discriminator Loss: 0.7916700839996338\n",
            "Epoch 247, Generator Loss: 7.317683219909668, Discriminator Loss: 0.5964390635490417\n",
            "Epoch 248, Generator Loss: 2.4344944953918457, Discriminator Loss: 1.1021769046783447\n",
            "Epoch 249, Generator Loss: 8.466209411621094, Discriminator Loss: 0.015848223119974136\n",
            "Epoch 250, Generator Loss: 5.940910339355469, Discriminator Loss: 0.47773993015289307\n",
            "Epoch 251, Generator Loss: 3.8571643829345703, Discriminator Loss: 0.5575181841850281\n",
            "Epoch 252, Generator Loss: 3.323357343673706, Discriminator Loss: 0.8895208835601807\n",
            "Epoch 253, Generator Loss: 6.541404724121094, Discriminator Loss: 0.7041862607002258\n",
            "Epoch 254, Generator Loss: 7.117138385772705, Discriminator Loss: 0.408945232629776\n",
            "Epoch 255, Generator Loss: 5.4464569091796875, Discriminator Loss: 0.8715773820877075\n",
            "Epoch 256, Generator Loss: 3.1720635890960693, Discriminator Loss: 0.4504780173301697\n",
            "Epoch 257, Generator Loss: 2.790529727935791, Discriminator Loss: 0.9378789067268372\n",
            "Epoch 258, Generator Loss: 3.4278812408447266, Discriminator Loss: 1.0307179689407349\n",
            "Epoch 259, Generator Loss: 2.8807029724121094, Discriminator Loss: 0.8432440757751465\n",
            "Epoch 260, Generator Loss: 1.1947038173675537, Discriminator Loss: 1.7747609615325928\n",
            "Epoch 261, Generator Loss: 3.2861814498901367, Discriminator Loss: 1.1632341146469116\n",
            "Epoch 262, Generator Loss: 4.605379104614258, Discriminator Loss: 0.6962934136390686\n",
            "Epoch 263, Generator Loss: 2.4421048164367676, Discriminator Loss: 1.7965044975280762\n",
            "Epoch 264, Generator Loss: 2.9197564125061035, Discriminator Loss: 1.6281511783599854\n",
            "Epoch 265, Generator Loss: 5.348090171813965, Discriminator Loss: 1.254664421081543\n",
            "Epoch 266, Generator Loss: 3.769261360168457, Discriminator Loss: 0.7168574929237366\n",
            "Epoch 267, Generator Loss: 3.7640480995178223, Discriminator Loss: 0.837104320526123\n",
            "Epoch 268, Generator Loss: 5.060271263122559, Discriminator Loss: 0.5997613668441772\n",
            "Epoch 269, Generator Loss: 6.23090934753418, Discriminator Loss: 0.7189555168151855\n",
            "Epoch 270, Generator Loss: 6.649477958679199, Discriminator Loss: 2.044161796569824\n",
            "Epoch 271, Generator Loss: 10.604022026062012, Discriminator Loss: 1.9605869054794312\n",
            "Epoch 272, Generator Loss: 5.76334285736084, Discriminator Loss: 0.22217682003974915\n",
            "Epoch 273, Generator Loss: 4.659909248352051, Discriminator Loss: 0.7928246855735779\n",
            "Epoch 274, Generator Loss: 4.431704521179199, Discriminator Loss: 0.7661581039428711\n",
            "Epoch 275, Generator Loss: 4.37117338180542, Discriminator Loss: 1.008026123046875\n",
            "Epoch 276, Generator Loss: 1.6332063674926758, Discriminator Loss: 2.0900449752807617\n",
            "Epoch 277, Generator Loss: 0.7602717280387878, Discriminator Loss: 2.5105412006378174\n",
            "Epoch 278, Generator Loss: 0.751515805721283, Discriminator Loss: 1.979282021522522\n",
            "Epoch 279, Generator Loss: 2.3069701194763184, Discriminator Loss: 1.1004502773284912\n",
            "Epoch 280, Generator Loss: 1.9625815153121948, Discriminator Loss: 1.9547755718231201\n",
            "Epoch 281, Generator Loss: 4.347508430480957, Discriminator Loss: 0.6316352486610413\n",
            "Epoch 282, Generator Loss: 4.616869926452637, Discriminator Loss: 1.2340253591537476\n",
            "Epoch 283, Generator Loss: 3.5905802249908447, Discriminator Loss: 1.194704532623291\n",
            "Epoch 284, Generator Loss: 5.464431285858154, Discriminator Loss: 0.5336544513702393\n",
            "Epoch 285, Generator Loss: 3.059511661529541, Discriminator Loss: 0.6481426954269409\n",
            "Epoch 286, Generator Loss: 5.027305603027344, Discriminator Loss: 0.7711526155471802\n",
            "Epoch 287, Generator Loss: 4.32100248336792, Discriminator Loss: 1.3183748722076416\n",
            "Epoch 288, Generator Loss: 2.192866325378418, Discriminator Loss: 1.5692131519317627\n",
            "Epoch 289, Generator Loss: 2.615445375442505, Discriminator Loss: 1.2886683940887451\n",
            "Epoch 290, Generator Loss: 3.000359058380127, Discriminator Loss: 1.3630390167236328\n",
            "Epoch 291, Generator Loss: 2.631605386734009, Discriminator Loss: 1.7742440700531006\n",
            "Epoch 292, Generator Loss: 2.3699800968170166, Discriminator Loss: 1.6014833450317383\n",
            "Epoch 293, Generator Loss: 3.954904079437256, Discriminator Loss: 0.8239274024963379\n",
            "Epoch 294, Generator Loss: 2.892169952392578, Discriminator Loss: 0.8093138337135315\n",
            "Epoch 295, Generator Loss: 3.1275875568389893, Discriminator Loss: 0.8207793831825256\n",
            "Epoch 296, Generator Loss: 2.895834445953369, Discriminator Loss: 1.7727978229522705\n",
            "Epoch 297, Generator Loss: 4.8918256759643555, Discriminator Loss: 1.586747407913208\n",
            "Epoch 298, Generator Loss: 3.0909311771392822, Discriminator Loss: 1.0344300270080566\n",
            "Epoch 299, Generator Loss: 1.280927062034607, Discriminator Loss: 2.1659581661224365\n",
            "Epoch 300, Generator Loss: 0.9517621397972107, Discriminator Loss: 2.448418140411377\n",
            "Epoch 301, Generator Loss: 1.848661184310913, Discriminator Loss: 1.5690147876739502\n",
            "Epoch 302, Generator Loss: 3.7452001571655273, Discriminator Loss: 1.0745854377746582\n",
            "Epoch 303, Generator Loss: 5.046741008758545, Discriminator Loss: 0.8893094062805176\n",
            "Epoch 304, Generator Loss: 2.819713592529297, Discriminator Loss: 1.0771961212158203\n",
            "Epoch 305, Generator Loss: 6.366581916809082, Discriminator Loss: 2.180802822113037\n",
            "Epoch 306, Generator Loss: 8.556288719177246, Discriminator Loss: 2.4018325805664062\n",
            "Epoch 307, Generator Loss: 5.861405372619629, Discriminator Loss: 2.1075077056884766\n",
            "Epoch 308, Generator Loss: 4.1534528732299805, Discriminator Loss: 1.5836795568466187\n",
            "Epoch 309, Generator Loss: 3.8943023681640625, Discriminator Loss: 1.3035271167755127\n",
            "Epoch 310, Generator Loss: 1.848448395729065, Discriminator Loss: 2.0351102352142334\n",
            "Epoch 311, Generator Loss: 3.697174072265625, Discriminator Loss: 0.5077911615371704\n",
            "Epoch 312, Generator Loss: 3.837909698486328, Discriminator Loss: 1.5281572341918945\n",
            "Epoch 313, Generator Loss: 5.7515363693237305, Discriminator Loss: 1.6217108964920044\n",
            "Epoch 314, Generator Loss: 2.9398159980773926, Discriminator Loss: 1.3992695808410645\n",
            "Epoch 315, Generator Loss: 1.94761061668396, Discriminator Loss: 0.8422191739082336\n",
            "Epoch 316, Generator Loss: 2.0531957149505615, Discriminator Loss: 1.428044319152832\n",
            "Epoch 317, Generator Loss: 2.047443151473999, Discriminator Loss: 1.462049961090088\n",
            "Epoch 318, Generator Loss: 2.0016157627105713, Discriminator Loss: 1.7360984086990356\n",
            "Epoch 319, Generator Loss: 2.532089948654175, Discriminator Loss: 1.356307029724121\n",
            "Epoch 320, Generator Loss: 1.4953339099884033, Discriminator Loss: 1.528161644935608\n",
            "Epoch 321, Generator Loss: 1.5287771224975586, Discriminator Loss: 1.7653687000274658\n",
            "Epoch 322, Generator Loss: 1.93967866897583, Discriminator Loss: 1.6342425346374512\n",
            "Epoch 323, Generator Loss: 3.8225936889648438, Discriminator Loss: 0.9895342588424683\n",
            "Epoch 324, Generator Loss: 2.7591559886932373, Discriminator Loss: 1.455362319946289\n",
            "Epoch 325, Generator Loss: 1.4300901889801025, Discriminator Loss: 1.8188834190368652\n",
            "Epoch 326, Generator Loss: 3.681767225265503, Discriminator Loss: 1.5340478420257568\n",
            "Epoch 327, Generator Loss: 4.286774635314941, Discriminator Loss: 2.8580617904663086\n",
            "Epoch 328, Generator Loss: 4.010316371917725, Discriminator Loss: 1.1454719305038452\n",
            "Epoch 329, Generator Loss: 3.6095900535583496, Discriminator Loss: 1.5202360153198242\n",
            "Epoch 330, Generator Loss: 5.671110153198242, Discriminator Loss: 2.9090168476104736\n",
            "Epoch 331, Generator Loss: 2.7029757499694824, Discriminator Loss: 1.408011794090271\n",
            "Epoch 332, Generator Loss: 1.5627732276916504, Discriminator Loss: 1.5299137830734253\n",
            "Epoch 333, Generator Loss: 2.1487481594085693, Discriminator Loss: 1.2884167432785034\n",
            "Epoch 334, Generator Loss: 1.2243385314941406, Discriminator Loss: 1.0747044086456299\n",
            "Epoch 335, Generator Loss: 1.2349025011062622, Discriminator Loss: 0.9899750351905823\n",
            "Epoch 336, Generator Loss: 2.162177085876465, Discriminator Loss: 1.1752080917358398\n",
            "Epoch 337, Generator Loss: 0.9930169582366943, Discriminator Loss: 1.262044072151184\n",
            "Epoch 338, Generator Loss: 1.7976926565170288, Discriminator Loss: 1.3308100700378418\n",
            "Epoch 339, Generator Loss: 2.236982583999634, Discriminator Loss: 1.5272279977798462\n",
            "Epoch 340, Generator Loss: 2.300896167755127, Discriminator Loss: 1.297248363494873\n",
            "Epoch 341, Generator Loss: 1.0229188203811646, Discriminator Loss: 1.876570701599121\n",
            "Epoch 342, Generator Loss: 2.2390482425689697, Discriminator Loss: 1.5342345237731934\n",
            "Epoch 343, Generator Loss: 1.5001695156097412, Discriminator Loss: 1.677431344985962\n",
            "Epoch 344, Generator Loss: 1.8981764316558838, Discriminator Loss: 2.2695400714874268\n",
            "Epoch 345, Generator Loss: 1.8892790079116821, Discriminator Loss: 1.4802303314208984\n",
            "Epoch 346, Generator Loss: 3.376260757446289, Discriminator Loss: 0.8369488716125488\n",
            "Epoch 347, Generator Loss: 2.657111644744873, Discriminator Loss: 1.1712119579315186\n",
            "Epoch 348, Generator Loss: 2.7789359092712402, Discriminator Loss: 1.8576619625091553\n",
            "Epoch 349, Generator Loss: 3.3564000129699707, Discriminator Loss: 1.2906827926635742\n",
            "Epoch 350, Generator Loss: 4.4846296310424805, Discriminator Loss: 2.066005229949951\n",
            "Epoch 351, Generator Loss: 2.8433446884155273, Discriminator Loss: 1.5120854377746582\n",
            "Epoch 352, Generator Loss: 3.992486000061035, Discriminator Loss: 0.4927312135696411\n",
            "Epoch 353, Generator Loss: 3.9968857765197754, Discriminator Loss: 2.2938902378082275\n",
            "Epoch 354, Generator Loss: 4.017115116119385, Discriminator Loss: 0.8654484748840332\n",
            "Epoch 355, Generator Loss: 2.73362398147583, Discriminator Loss: 1.2994550466537476\n",
            "Epoch 356, Generator Loss: 2.88297176361084, Discriminator Loss: 1.085262417793274\n",
            "Epoch 357, Generator Loss: 3.6815948486328125, Discriminator Loss: 0.9734671115875244\n",
            "Epoch 358, Generator Loss: 3.5629220008850098, Discriminator Loss: 1.2141882181167603\n",
            "Epoch 359, Generator Loss: 3.874556303024292, Discriminator Loss: 0.7999058365821838\n",
            "Epoch 360, Generator Loss: 3.29158353805542, Discriminator Loss: 1.67543363571167\n",
            "Epoch 361, Generator Loss: 1.918065071105957, Discriminator Loss: 1.1994515657424927\n",
            "Epoch 362, Generator Loss: 2.873680353164673, Discriminator Loss: 1.210644006729126\n",
            "Epoch 363, Generator Loss: 2.026796340942383, Discriminator Loss: 1.901047945022583\n",
            "Epoch 364, Generator Loss: 1.3093030452728271, Discriminator Loss: 1.7284574508666992\n",
            "Epoch 365, Generator Loss: 3.540290117263794, Discriminator Loss: 1.138789415359497\n",
            "Epoch 366, Generator Loss: 2.657266855239868, Discriminator Loss: 0.885294497013092\n",
            "Epoch 367, Generator Loss: 3.0379855632781982, Discriminator Loss: 0.8260217905044556\n",
            "Epoch 368, Generator Loss: 2.7441599369049072, Discriminator Loss: 0.8734335899353027\n",
            "Epoch 369, Generator Loss: 3.664846181869507, Discriminator Loss: 0.9556854963302612\n",
            "Epoch 370, Generator Loss: 7.536184310913086, Discriminator Loss: 0.9482272863388062\n",
            "Epoch 371, Generator Loss: 5.49151086807251, Discriminator Loss: 1.7064870595932007\n",
            "Epoch 372, Generator Loss: 5.568088531494141, Discriminator Loss: 1.4501198530197144\n",
            "Epoch 373, Generator Loss: 5.765068531036377, Discriminator Loss: 1.4118478298187256\n",
            "Epoch 374, Generator Loss: 5.577350616455078, Discriminator Loss: 1.1876968145370483\n",
            "Epoch 375, Generator Loss: 4.438144683837891, Discriminator Loss: 1.1167773008346558\n",
            "Epoch 376, Generator Loss: 2.661686897277832, Discriminator Loss: 1.2484049797058105\n",
            "Epoch 377, Generator Loss: 3.1703293323516846, Discriminator Loss: 1.7533670663833618\n",
            "Epoch 378, Generator Loss: 2.9615163803100586, Discriminator Loss: 1.5512819290161133\n",
            "Epoch 379, Generator Loss: 1.993269443511963, Discriminator Loss: 1.0077202320098877\n",
            "Epoch 380, Generator Loss: 0.8036344647407532, Discriminator Loss: 1.9801597595214844\n",
            "Epoch 381, Generator Loss: 1.0309739112854004, Discriminator Loss: 1.1934844255447388\n",
            "Epoch 382, Generator Loss: 1.9186182022094727, Discriminator Loss: 0.8007481694221497\n",
            "Epoch 383, Generator Loss: 2.179075241088867, Discriminator Loss: 0.9101226329803467\n",
            "Epoch 384, Generator Loss: 3.2511134147644043, Discriminator Loss: 1.1233478784561157\n",
            "Epoch 385, Generator Loss: 4.059675216674805, Discriminator Loss: 0.6132327318191528\n",
            "Epoch 386, Generator Loss: 2.8774185180664062, Discriminator Loss: 1.329927921295166\n",
            "Epoch 387, Generator Loss: 3.38802433013916, Discriminator Loss: 1.1851485967636108\n",
            "Epoch 388, Generator Loss: 2.558206081390381, Discriminator Loss: 1.537227988243103\n",
            "Epoch 389, Generator Loss: 4.925963878631592, Discriminator Loss: 1.727776050567627\n",
            "Epoch 390, Generator Loss: 3.493833541870117, Discriminator Loss: 1.4090003967285156\n",
            "Epoch 391, Generator Loss: 3.3425211906433105, Discriminator Loss: 1.1161075830459595\n",
            "Epoch 392, Generator Loss: 2.5958077907562256, Discriminator Loss: 1.135257601737976\n",
            "Epoch 393, Generator Loss: 2.067448616027832, Discriminator Loss: 1.0407427549362183\n",
            "Epoch 394, Generator Loss: 1.034265398979187, Discriminator Loss: 1.5307718515396118\n",
            "Epoch 395, Generator Loss: 1.849879503250122, Discriminator Loss: 0.8951795697212219\n",
            "Epoch 396, Generator Loss: 1.9331779479980469, Discriminator Loss: 1.0442616939544678\n",
            "Epoch 397, Generator Loss: 2.269115447998047, Discriminator Loss: 0.8971601724624634\n",
            "Epoch 398, Generator Loss: 2.175853729248047, Discriminator Loss: 1.031968593597412\n",
            "Epoch 399, Generator Loss: 2.337315797805786, Discriminator Loss: 0.7647168636322021\n",
            "Epoch 400, Generator Loss: 2.96095609664917, Discriminator Loss: 1.0081660747528076\n",
            "Epoch 401, Generator Loss: 3.114063024520874, Discriminator Loss: 0.672896146774292\n",
            "Epoch 402, Generator Loss: 3.7189419269561768, Discriminator Loss: 1.3776673078536987\n",
            "Epoch 403, Generator Loss: 4.042075157165527, Discriminator Loss: 1.2207942008972168\n",
            "Epoch 404, Generator Loss: 5.428475379943848, Discriminator Loss: 2.1579885482788086\n",
            "Epoch 405, Generator Loss: 4.646533489227295, Discriminator Loss: 2.09555983543396\n",
            "Epoch 406, Generator Loss: 4.492559432983398, Discriminator Loss: 0.8859535455703735\n",
            "Epoch 407, Generator Loss: 2.19309663772583, Discriminator Loss: 0.811388373374939\n",
            "Epoch 408, Generator Loss: 3.287086009979248, Discriminator Loss: 0.9144320487976074\n",
            "Epoch 409, Generator Loss: 2.4584648609161377, Discriminator Loss: 0.7757923007011414\n",
            "Epoch 410, Generator Loss: 1.6555097103118896, Discriminator Loss: 1.6928904056549072\n",
            "Epoch 411, Generator Loss: 2.1409599781036377, Discriminator Loss: 1.0444048643112183\n",
            "Epoch 412, Generator Loss: 3.6070668697357178, Discriminator Loss: 0.9008440375328064\n",
            "Epoch 413, Generator Loss: 3.515364170074463, Discriminator Loss: 1.1639522314071655\n",
            "Epoch 414, Generator Loss: 2.5027308464050293, Discriminator Loss: 0.7468444108963013\n",
            "Epoch 415, Generator Loss: 3.3271939754486084, Discriminator Loss: 1.10960853099823\n",
            "Epoch 416, Generator Loss: 3.483431577682495, Discriminator Loss: 0.6259996294975281\n",
            "Epoch 417, Generator Loss: 1.5264995098114014, Discriminator Loss: 1.4889929294586182\n",
            "Epoch 418, Generator Loss: 1.8194175958633423, Discriminator Loss: 1.3284673690795898\n",
            "Epoch 419, Generator Loss: 2.3420422077178955, Discriminator Loss: 1.5640902519226074\n",
            "Epoch 420, Generator Loss: 4.054619789123535, Discriminator Loss: 1.0389732122421265\n",
            "Epoch 421, Generator Loss: 2.7913780212402344, Discriminator Loss: 1.2830350399017334\n",
            "Epoch 422, Generator Loss: 1.80438232421875, Discriminator Loss: 1.3529636859893799\n",
            "Epoch 423, Generator Loss: 1.4628276824951172, Discriminator Loss: 1.7524588108062744\n",
            "Epoch 424, Generator Loss: 1.753773808479309, Discriminator Loss: 1.0757038593292236\n",
            "Epoch 425, Generator Loss: 2.910921573638916, Discriminator Loss: 1.0837161540985107\n",
            "Epoch 426, Generator Loss: 1.9008427858352661, Discriminator Loss: 0.9275906085968018\n",
            "Epoch 427, Generator Loss: 2.5561232566833496, Discriminator Loss: 0.782416582107544\n",
            "Epoch 428, Generator Loss: 2.830127000808716, Discriminator Loss: 1.4983383417129517\n",
            "Epoch 429, Generator Loss: 2.9013335704803467, Discriminator Loss: 1.308837890625\n",
            "Epoch 430, Generator Loss: 2.7634992599487305, Discriminator Loss: 0.8606454133987427\n",
            "Epoch 431, Generator Loss: 2.84367299079895, Discriminator Loss: 0.8383651971817017\n",
            "Epoch 432, Generator Loss: 3.0885212421417236, Discriminator Loss: 0.7180899381637573\n",
            "Epoch 433, Generator Loss: 1.9434270858764648, Discriminator Loss: 0.8019863963127136\n",
            "Epoch 434, Generator Loss: 2.5717101097106934, Discriminator Loss: 1.3329734802246094\n",
            "Epoch 435, Generator Loss: 2.9978199005126953, Discriminator Loss: 1.2161486148834229\n",
            "Epoch 436, Generator Loss: 4.453397274017334, Discriminator Loss: 0.6062399744987488\n",
            "Epoch 437, Generator Loss: 6.552427291870117, Discriminator Loss: 2.991447687149048\n",
            "Epoch 438, Generator Loss: 4.703186988830566, Discriminator Loss: 1.0564403533935547\n",
            "Epoch 439, Generator Loss: 3.8797390460968018, Discriminator Loss: 0.5209076404571533\n",
            "Epoch 440, Generator Loss: 5.41400146484375, Discriminator Loss: 1.6931025981903076\n",
            "Epoch 441, Generator Loss: 5.463788986206055, Discriminator Loss: 1.3070532083511353\n",
            "Epoch 442, Generator Loss: 3.766578197479248, Discriminator Loss: 0.9612650871276855\n",
            "Epoch 443, Generator Loss: 4.0502519607543945, Discriminator Loss: 0.6728653907775879\n",
            "Epoch 444, Generator Loss: 2.6774795055389404, Discriminator Loss: 0.7722455263137817\n",
            "Epoch 445, Generator Loss: 2.481614828109741, Discriminator Loss: 0.767998218536377\n",
            "Epoch 446, Generator Loss: 2.727379560470581, Discriminator Loss: 0.6777985095977783\n",
            "Epoch 447, Generator Loss: 1.9575467109680176, Discriminator Loss: 1.1511000394821167\n",
            "Epoch 448, Generator Loss: 3.4132676124572754, Discriminator Loss: 2.0454518795013428\n",
            "Epoch 449, Generator Loss: 1.9125584363937378, Discriminator Loss: 1.104874849319458\n",
            "Epoch 450, Generator Loss: 2.059993028640747, Discriminator Loss: 0.9494554996490479\n",
            "Epoch 451, Generator Loss: 4.488849639892578, Discriminator Loss: 0.6146900653839111\n",
            "Epoch 452, Generator Loss: 3.315460443496704, Discriminator Loss: 1.0731315612792969\n",
            "Epoch 453, Generator Loss: 2.6524505615234375, Discriminator Loss: 0.8766926527023315\n",
            "Epoch 454, Generator Loss: 2.567289352416992, Discriminator Loss: 1.4202923774719238\n",
            "Epoch 455, Generator Loss: 1.169585943222046, Discriminator Loss: 1.3323038816452026\n",
            "Epoch 456, Generator Loss: 2.1146342754364014, Discriminator Loss: 0.8926063179969788\n",
            "Epoch 457, Generator Loss: 2.4097788333892822, Discriminator Loss: 0.8494952321052551\n",
            "Epoch 458, Generator Loss: 2.832993984222412, Discriminator Loss: 1.0382685661315918\n",
            "Epoch 459, Generator Loss: 1.5583906173706055, Discriminator Loss: 1.6487290859222412\n",
            "Epoch 460, Generator Loss: 2.312412977218628, Discriminator Loss: 0.7777808904647827\n",
            "Epoch 461, Generator Loss: 2.467510223388672, Discriminator Loss: 1.500338077545166\n",
            "Epoch 462, Generator Loss: 4.667006969451904, Discriminator Loss: 0.6786355376243591\n",
            "Epoch 463, Generator Loss: 4.572065353393555, Discriminator Loss: 2.116037607192993\n",
            "Epoch 464, Generator Loss: 3.4467334747314453, Discriminator Loss: 1.0710461139678955\n",
            "Epoch 465, Generator Loss: 2.608295440673828, Discriminator Loss: 1.2735497951507568\n",
            "Epoch 466, Generator Loss: 3.3084399700164795, Discriminator Loss: 0.4221007227897644\n",
            "Epoch 467, Generator Loss: 2.5692811012268066, Discriminator Loss: 0.634036123752594\n",
            "Epoch 468, Generator Loss: 3.280604362487793, Discriminator Loss: 0.7394075393676758\n",
            "Epoch 469, Generator Loss: 4.553327560424805, Discriminator Loss: 0.6235527396202087\n",
            "Epoch 470, Generator Loss: 2.351245641708374, Discriminator Loss: 0.587939441204071\n",
            "Epoch 471, Generator Loss: 3.5432324409484863, Discriminator Loss: 0.8692699670791626\n",
            "Epoch 472, Generator Loss: 2.091047525405884, Discriminator Loss: 0.8501447439193726\n",
            "Epoch 473, Generator Loss: 3.422430992126465, Discriminator Loss: 1.1111359596252441\n",
            "Epoch 474, Generator Loss: 3.6968231201171875, Discriminator Loss: 0.48879337310791016\n",
            "Epoch 475, Generator Loss: 3.6381821632385254, Discriminator Loss: 1.1981825828552246\n",
            "Epoch 476, Generator Loss: 3.4409074783325195, Discriminator Loss: 1.2283339500427246\n",
            "Epoch 477, Generator Loss: 2.517223358154297, Discriminator Loss: 0.6835871934890747\n",
            "Epoch 478, Generator Loss: 5.044541358947754, Discriminator Loss: 1.5426322221755981\n",
            "Epoch 479, Generator Loss: 3.8028016090393066, Discriminator Loss: 1.078984022140503\n",
            "Epoch 480, Generator Loss: 3.1578750610351562, Discriminator Loss: 0.6459420919418335\n",
            "Epoch 481, Generator Loss: 1.863250494003296, Discriminator Loss: 1.1921757459640503\n",
            "Epoch 482, Generator Loss: 3.0380630493164062, Discriminator Loss: 1.0362385511398315\n",
            "Epoch 483, Generator Loss: 1.9783899784088135, Discriminator Loss: 1.087913990020752\n",
            "Epoch 484, Generator Loss: 1.839963674545288, Discriminator Loss: 1.0058578252792358\n",
            "Epoch 485, Generator Loss: 2.615360975265503, Discriminator Loss: 0.8103374242782593\n",
            "Epoch 486, Generator Loss: 2.429722309112549, Discriminator Loss: 1.0079153776168823\n",
            "Epoch 487, Generator Loss: 1.8766934871673584, Discriminator Loss: 1.16764497756958\n",
            "Epoch 488, Generator Loss: 1.9531679153442383, Discriminator Loss: 1.359712839126587\n",
            "Epoch 489, Generator Loss: 2.879952907562256, Discriminator Loss: 0.4928198754787445\n",
            "Epoch 490, Generator Loss: 3.4799816608428955, Discriminator Loss: 0.675103485584259\n",
            "Epoch 491, Generator Loss: 2.9589531421661377, Discriminator Loss: 0.6465193033218384\n",
            "Epoch 492, Generator Loss: 2.5440430641174316, Discriminator Loss: 0.7642356157302856\n",
            "Epoch 493, Generator Loss: 2.168794631958008, Discriminator Loss: 0.6509290933609009\n",
            "Epoch 494, Generator Loss: 1.7997796535491943, Discriminator Loss: 0.9287299513816833\n",
            "Epoch 495, Generator Loss: 2.9519548416137695, Discriminator Loss: 0.7371945381164551\n",
            "Epoch 496, Generator Loss: 3.058354139328003, Discriminator Loss: 0.9722505807876587\n",
            "Epoch 497, Generator Loss: 2.234187364578247, Discriminator Loss: 1.1482207775115967\n",
            "Epoch 498, Generator Loss: 1.5987520217895508, Discriminator Loss: 1.484925389289856\n",
            "Epoch 499, Generator Loss: 2.811164379119873, Discriminator Loss: 0.6607915163040161\n",
            "Epoch 500, Generator Loss: 4.112606048583984, Discriminator Loss: 0.6808760166168213\n",
            "Epoch 501, Generator Loss: 2.671384572982788, Discriminator Loss: 1.545668125152588\n",
            "Epoch 502, Generator Loss: 3.099364757537842, Discriminator Loss: 0.7592099905014038\n",
            "Epoch 503, Generator Loss: 4.35154914855957, Discriminator Loss: 1.4912956953048706\n",
            "Epoch 504, Generator Loss: 4.115551948547363, Discriminator Loss: 1.1073243618011475\n",
            "Epoch 505, Generator Loss: 4.274184226989746, Discriminator Loss: 0.8767679929733276\n",
            "Epoch 506, Generator Loss: 3.639615297317505, Discriminator Loss: 1.174638032913208\n",
            "Epoch 507, Generator Loss: 1.8679397106170654, Discriminator Loss: 1.072349190711975\n",
            "Epoch 508, Generator Loss: 1.5175853967666626, Discriminator Loss: 0.9886191487312317\n",
            "Epoch 509, Generator Loss: 1.6664979457855225, Discriminator Loss: 0.9597442150115967\n",
            "Epoch 510, Generator Loss: 2.583493232727051, Discriminator Loss: 1.370067834854126\n",
            "Epoch 511, Generator Loss: 2.8967809677124023, Discriminator Loss: 0.639428973197937\n",
            "Epoch 512, Generator Loss: 3.2241005897521973, Discriminator Loss: 0.7467159032821655\n",
            "Epoch 513, Generator Loss: 3.8198728561401367, Discriminator Loss: 1.0491983890533447\n",
            "Epoch 514, Generator Loss: 3.3247828483581543, Discriminator Loss: 1.7249048948287964\n",
            "Epoch 515, Generator Loss: 2.3970212936401367, Discriminator Loss: 0.8555871248245239\n",
            "Epoch 516, Generator Loss: 3.5127906799316406, Discriminator Loss: 0.561677098274231\n",
            "Epoch 517, Generator Loss: 2.272273540496826, Discriminator Loss: 0.7064260244369507\n",
            "Epoch 518, Generator Loss: 1.5479612350463867, Discriminator Loss: 0.9309848546981812\n",
            "Epoch 519, Generator Loss: 1.7643810510635376, Discriminator Loss: 0.8590918183326721\n",
            "Epoch 520, Generator Loss: 2.4246325492858887, Discriminator Loss: 0.5651262402534485\n",
            "Epoch 521, Generator Loss: 2.4479172229766846, Discriminator Loss: 0.7419711947441101\n",
            "Epoch 522, Generator Loss: 4.232028007507324, Discriminator Loss: 1.375896692276001\n",
            "Epoch 523, Generator Loss: 4.176047325134277, Discriminator Loss: 0.45412030816078186\n",
            "Epoch 524, Generator Loss: 2.527052164077759, Discriminator Loss: 1.3135064840316772\n",
            "Epoch 525, Generator Loss: 2.149599313735962, Discriminator Loss: 1.1701472997665405\n",
            "Epoch 526, Generator Loss: 2.8582372665405273, Discriminator Loss: 1.287369728088379\n",
            "Epoch 527, Generator Loss: 3.5121052265167236, Discriminator Loss: 0.8208996057510376\n",
            "Epoch 528, Generator Loss: 2.5655319690704346, Discriminator Loss: 0.6135712265968323\n",
            "Epoch 529, Generator Loss: 2.8642921447753906, Discriminator Loss: 1.0684975385665894\n",
            "Epoch 530, Generator Loss: 2.716710090637207, Discriminator Loss: 0.8867145776748657\n",
            "Epoch 531, Generator Loss: 2.7359845638275146, Discriminator Loss: 0.6210739612579346\n",
            "Epoch 532, Generator Loss: 1.3552262783050537, Discriminator Loss: 1.0208029747009277\n",
            "Epoch 533, Generator Loss: 2.0622451305389404, Discriminator Loss: 0.9430737495422363\n",
            "Epoch 534, Generator Loss: 2.2517130374908447, Discriminator Loss: 0.7470204830169678\n",
            "Epoch 535, Generator Loss: 2.0679593086242676, Discriminator Loss: 0.872414231300354\n",
            "Epoch 536, Generator Loss: 3.402554512023926, Discriminator Loss: 1.1658798456192017\n",
            "Epoch 537, Generator Loss: 2.443772792816162, Discriminator Loss: 0.5309773683547974\n",
            "Epoch 538, Generator Loss: 2.7841639518737793, Discriminator Loss: 0.538371205329895\n",
            "Epoch 539, Generator Loss: 2.0067577362060547, Discriminator Loss: 0.7963011264801025\n",
            "Epoch 540, Generator Loss: 2.707503318786621, Discriminator Loss: 1.2023875713348389\n",
            "Epoch 541, Generator Loss: 1.7681334018707275, Discriminator Loss: 0.763690710067749\n",
            "Epoch 542, Generator Loss: 1.489564061164856, Discriminator Loss: 1.936061143875122\n",
            "Epoch 543, Generator Loss: 1.986494541168213, Discriminator Loss: 1.061639428138733\n",
            "Epoch 544, Generator Loss: 2.777378559112549, Discriminator Loss: 0.6470096707344055\n",
            "Epoch 545, Generator Loss: 2.5388379096984863, Discriminator Loss: 0.6687782406806946\n",
            "Epoch 546, Generator Loss: 1.9935863018035889, Discriminator Loss: 1.4077684879302979\n",
            "Epoch 547, Generator Loss: 2.5106077194213867, Discriminator Loss: 0.7317216396331787\n",
            "Epoch 548, Generator Loss: 1.824981451034546, Discriminator Loss: 0.8452842235565186\n",
            "Epoch 549, Generator Loss: 5.4017791748046875, Discriminator Loss: 1.284339427947998\n",
            "Epoch 550, Generator Loss: 3.037886142730713, Discriminator Loss: 0.47815823554992676\n",
            "Epoch 551, Generator Loss: 4.17845344543457, Discriminator Loss: 1.5550105571746826\n",
            "Epoch 552, Generator Loss: 3.658090114593506, Discriminator Loss: 0.5821837782859802\n",
            "Epoch 553, Generator Loss: 2.281029224395752, Discriminator Loss: 0.8026984930038452\n",
            "Epoch 554, Generator Loss: 1.9869637489318848, Discriminator Loss: 0.9288377165794373\n",
            "Epoch 555, Generator Loss: 2.956322193145752, Discriminator Loss: 0.8327395915985107\n",
            "Epoch 556, Generator Loss: 2.164903402328491, Discriminator Loss: 0.7533961534500122\n",
            "Epoch 557, Generator Loss: 3.592984437942505, Discriminator Loss: 1.0506558418273926\n",
            "Epoch 558, Generator Loss: 2.2358784675598145, Discriminator Loss: 0.801525354385376\n",
            "Epoch 559, Generator Loss: 3.1414237022399902, Discriminator Loss: 1.0855801105499268\n",
            "Epoch 560, Generator Loss: 1.4780869483947754, Discriminator Loss: 0.8376665115356445\n",
            "Epoch 561, Generator Loss: 2.2127676010131836, Discriminator Loss: 0.7528728246688843\n",
            "Epoch 562, Generator Loss: 2.224151611328125, Discriminator Loss: 0.6396441459655762\n",
            "Epoch 563, Generator Loss: 3.17514705657959, Discriminator Loss: 0.4348216652870178\n",
            "Epoch 564, Generator Loss: 1.9013144969940186, Discriminator Loss: 0.707779049873352\n",
            "Epoch 565, Generator Loss: 1.4613885879516602, Discriminator Loss: 1.1535009145736694\n",
            "Epoch 566, Generator Loss: 2.7253499031066895, Discriminator Loss: 1.141033411026001\n",
            "Epoch 567, Generator Loss: 2.3721635341644287, Discriminator Loss: 0.5201278924942017\n",
            "Epoch 568, Generator Loss: 4.661684036254883, Discriminator Loss: 0.30569377541542053\n",
            "Epoch 569, Generator Loss: 3.194239377975464, Discriminator Loss: 0.9632883071899414\n",
            "Epoch 570, Generator Loss: 3.404791831970215, Discriminator Loss: 0.9839765429496765\n",
            "Epoch 571, Generator Loss: 3.2741785049438477, Discriminator Loss: 0.6034833192825317\n",
            "Epoch 572, Generator Loss: 2.663832426071167, Discriminator Loss: 0.5498777627944946\n",
            "Epoch 573, Generator Loss: 2.6391923427581787, Discriminator Loss: 1.264784812927246\n",
            "Epoch 574, Generator Loss: 3.0361850261688232, Discriminator Loss: 1.6840333938598633\n",
            "Epoch 575, Generator Loss: 3.0261569023132324, Discriminator Loss: 1.399365782737732\n",
            "Epoch 576, Generator Loss: 2.7801342010498047, Discriminator Loss: 1.2451982498168945\n",
            "Epoch 577, Generator Loss: 2.428042411804199, Discriminator Loss: 0.8641476631164551\n",
            "Epoch 578, Generator Loss: 3.6723508834838867, Discriminator Loss: 0.8832830190658569\n",
            "Epoch 579, Generator Loss: 1.8319127559661865, Discriminator Loss: 0.734400749206543\n",
            "Epoch 580, Generator Loss: 1.9524660110473633, Discriminator Loss: 0.98480224609375\n",
            "Epoch 581, Generator Loss: 3.1067895889282227, Discriminator Loss: 0.9206480979919434\n",
            "Epoch 582, Generator Loss: 2.924111843109131, Discriminator Loss: 0.8731886148452759\n",
            "Epoch 583, Generator Loss: 2.1939263343811035, Discriminator Loss: 1.3454958200454712\n",
            "Epoch 584, Generator Loss: 2.0228195190429688, Discriminator Loss: 0.7936742305755615\n",
            "Epoch 585, Generator Loss: 3.154440402984619, Discriminator Loss: 0.9659422636032104\n",
            "Epoch 586, Generator Loss: 1.6708910465240479, Discriminator Loss: 0.9843623042106628\n",
            "Epoch 587, Generator Loss: 1.8440606594085693, Discriminator Loss: 0.4898710250854492\n",
            "Epoch 588, Generator Loss: 2.38311505317688, Discriminator Loss: 0.8542601466178894\n",
            "Epoch 589, Generator Loss: 3.0641677379608154, Discriminator Loss: 0.8621540069580078\n",
            "Epoch 590, Generator Loss: 2.901369571685791, Discriminator Loss: 1.2342023849487305\n",
            "Epoch 591, Generator Loss: 1.5917203426361084, Discriminator Loss: 1.127012014389038\n",
            "Epoch 592, Generator Loss: 0.7942471504211426, Discriminator Loss: 1.9399185180664062\n",
            "Epoch 593, Generator Loss: 1.9086885452270508, Discriminator Loss: 1.1255298852920532\n",
            "Epoch 594, Generator Loss: 2.984792470932007, Discriminator Loss: 0.33466535806655884\n",
            "Epoch 595, Generator Loss: 2.9403345584869385, Discriminator Loss: 0.5410725474357605\n",
            "Epoch 596, Generator Loss: 2.8755006790161133, Discriminator Loss: 1.2141395807266235\n",
            "Epoch 597, Generator Loss: 1.6281769275665283, Discriminator Loss: 1.1670849323272705\n",
            "Epoch 598, Generator Loss: 1.3998898267745972, Discriminator Loss: 0.7859649658203125\n",
            "Epoch 599, Generator Loss: 3.0697293281555176, Discriminator Loss: 0.8724891543388367\n",
            "Epoch 600, Generator Loss: 2.3472177982330322, Discriminator Loss: 0.862113893032074\n",
            "Epoch 601, Generator Loss: 3.5930614471435547, Discriminator Loss: 0.7609862089157104\n",
            "Epoch 602, Generator Loss: 4.852758407592773, Discriminator Loss: 0.577019214630127\n",
            "Epoch 603, Generator Loss: 4.943453788757324, Discriminator Loss: 1.1331608295440674\n",
            "Epoch 604, Generator Loss: 3.807666778564453, Discriminator Loss: 0.9119091629981995\n",
            "Epoch 605, Generator Loss: 1.595193862915039, Discriminator Loss: 0.8929390907287598\n",
            "Epoch 606, Generator Loss: 2.131010055541992, Discriminator Loss: 0.752690851688385\n",
            "Epoch 607, Generator Loss: 2.7664382457733154, Discriminator Loss: 1.0092030763626099\n",
            "Epoch 608, Generator Loss: 2.804243564605713, Discriminator Loss: 0.7044500112533569\n",
            "Epoch 609, Generator Loss: 1.8705222606658936, Discriminator Loss: 1.244032859802246\n",
            "Epoch 610, Generator Loss: 2.691923141479492, Discriminator Loss: 0.6835007071495056\n",
            "Epoch 611, Generator Loss: 4.338881015777588, Discriminator Loss: 2.108603000640869\n",
            "Epoch 612, Generator Loss: 2.491576671600342, Discriminator Loss: 1.091507911682129\n",
            "Epoch 613, Generator Loss: 1.401785135269165, Discriminator Loss: 1.217320442199707\n",
            "Epoch 614, Generator Loss: 3.1485061645507812, Discriminator Loss: 0.698989748954773\n",
            "Epoch 615, Generator Loss: 3.78739857673645, Discriminator Loss: 1.2350566387176514\n",
            "Epoch 616, Generator Loss: 2.3354082107543945, Discriminator Loss: 0.6956930756568909\n",
            "Epoch 617, Generator Loss: 2.3290340900421143, Discriminator Loss: 0.725877046585083\n",
            "Epoch 618, Generator Loss: 3.488330125808716, Discriminator Loss: 0.7299557328224182\n",
            "Epoch 619, Generator Loss: 3.954662799835205, Discriminator Loss: 0.7967369556427002\n",
            "Epoch 620, Generator Loss: 3.5069222450256348, Discriminator Loss: 1.0278005599975586\n",
            "Epoch 621, Generator Loss: 2.5036516189575195, Discriminator Loss: 1.076758861541748\n",
            "Epoch 622, Generator Loss: 2.800507068634033, Discriminator Loss: 0.9767687916755676\n",
            "Epoch 623, Generator Loss: 2.5269858837127686, Discriminator Loss: 1.2700791358947754\n",
            "Epoch 624, Generator Loss: 1.537808895111084, Discriminator Loss: 0.9814838767051697\n",
            "Epoch 625, Generator Loss: 0.589817225933075, Discriminator Loss: 2.187595844268799\n",
            "Epoch 626, Generator Loss: 1.0351920127868652, Discriminator Loss: 1.5168920755386353\n",
            "Epoch 627, Generator Loss: 1.6667535305023193, Discriminator Loss: 1.0618417263031006\n",
            "Epoch 628, Generator Loss: 2.4224371910095215, Discriminator Loss: 0.7115070819854736\n",
            "Epoch 629, Generator Loss: 1.8522570133209229, Discriminator Loss: 1.1053335666656494\n",
            "Epoch 630, Generator Loss: 2.5920863151550293, Discriminator Loss: 0.9255635738372803\n",
            "Epoch 631, Generator Loss: 2.6449124813079834, Discriminator Loss: 0.9375192523002625\n",
            "Epoch 632, Generator Loss: 2.439253091812134, Discriminator Loss: 0.9365828037261963\n",
            "Epoch 633, Generator Loss: 1.3695515394210815, Discriminator Loss: 0.9998247027397156\n",
            "Epoch 634, Generator Loss: 1.5264490842819214, Discriminator Loss: 1.3492990732192993\n",
            "Epoch 635, Generator Loss: 2.5945498943328857, Discriminator Loss: 0.6868371963500977\n",
            "Epoch 636, Generator Loss: 2.6922149658203125, Discriminator Loss: 0.5834296345710754\n",
            "Epoch 637, Generator Loss: 3.7581255435943604, Discriminator Loss: 0.4723692536354065\n",
            "Epoch 638, Generator Loss: 5.087805271148682, Discriminator Loss: 1.8858058452606201\n",
            "Epoch 639, Generator Loss: 4.154188632965088, Discriminator Loss: 1.4800151586532593\n",
            "Epoch 640, Generator Loss: 3.5215282440185547, Discriminator Loss: 1.301027774810791\n",
            "Epoch 641, Generator Loss: 4.252602577209473, Discriminator Loss: 0.6567276120185852\n",
            "Epoch 642, Generator Loss: 4.043446063995361, Discriminator Loss: 1.0617237091064453\n",
            "Epoch 643, Generator Loss: 1.5085079669952393, Discriminator Loss: 1.1189465522766113\n",
            "Epoch 644, Generator Loss: 3.6927850246429443, Discriminator Loss: 1.1553168296813965\n",
            "Epoch 645, Generator Loss: 2.258995532989502, Discriminator Loss: 1.0433132648468018\n",
            "Epoch 646, Generator Loss: 1.752131700515747, Discriminator Loss: 0.5613109469413757\n",
            "Epoch 647, Generator Loss: 1.3039984703063965, Discriminator Loss: 1.156498670578003\n",
            "Epoch 648, Generator Loss: 1.1376394033432007, Discriminator Loss: 1.293567180633545\n",
            "Epoch 649, Generator Loss: 2.8028831481933594, Discriminator Loss: 1.169823169708252\n",
            "Epoch 650, Generator Loss: 3.968909740447998, Discriminator Loss: 1.1005202531814575\n",
            "Epoch 651, Generator Loss: 3.8332693576812744, Discriminator Loss: 0.8001546859741211\n",
            "Epoch 652, Generator Loss: 3.2840383052825928, Discriminator Loss: 0.6713917851448059\n",
            "Epoch 653, Generator Loss: 2.184945583343506, Discriminator Loss: 1.1791203022003174\n",
            "Epoch 654, Generator Loss: 2.5705766677856445, Discriminator Loss: 1.1267255544662476\n",
            "Epoch 655, Generator Loss: 1.9821312427520752, Discriminator Loss: 1.0351603031158447\n",
            "Epoch 656, Generator Loss: 2.505235433578491, Discriminator Loss: 1.5112837553024292\n",
            "Epoch 657, Generator Loss: 2.39400577545166, Discriminator Loss: 0.35817456245422363\n",
            "Epoch 658, Generator Loss: 2.605001449584961, Discriminator Loss: 0.8561532497406006\n",
            "Epoch 659, Generator Loss: 3.3801283836364746, Discriminator Loss: 0.8763130903244019\n",
            "Epoch 660, Generator Loss: 3.1880643367767334, Discriminator Loss: 0.45353126525878906\n",
            "Epoch 661, Generator Loss: 3.047053098678589, Discriminator Loss: 0.925147533416748\n",
            "Epoch 662, Generator Loss: 2.875985622406006, Discriminator Loss: 0.8649340867996216\n",
            "Epoch 663, Generator Loss: 2.8907084465026855, Discriminator Loss: 0.4277380704879761\n",
            "Epoch 664, Generator Loss: 3.3600611686706543, Discriminator Loss: 0.6393854022026062\n",
            "Epoch 665, Generator Loss: 1.818595051765442, Discriminator Loss: 0.8712604641914368\n",
            "Epoch 666, Generator Loss: 3.984067440032959, Discriminator Loss: 1.594982385635376\n",
            "Epoch 667, Generator Loss: 4.525391101837158, Discriminator Loss: 1.621190071105957\n",
            "Epoch 668, Generator Loss: 5.377564430236816, Discriminator Loss: 1.5131138563156128\n",
            "Epoch 669, Generator Loss: 4.3527021408081055, Discriminator Loss: 1.6550081968307495\n",
            "Epoch 670, Generator Loss: 2.183943510055542, Discriminator Loss: 0.981144905090332\n",
            "Epoch 671, Generator Loss: 3.1162965297698975, Discriminator Loss: 0.9292625784873962\n",
            "Epoch 672, Generator Loss: 2.979661464691162, Discriminator Loss: 0.8875039219856262\n",
            "Epoch 673, Generator Loss: 1.8335893154144287, Discriminator Loss: 0.9734134674072266\n",
            "Epoch 674, Generator Loss: 2.1366305351257324, Discriminator Loss: 0.9977377653121948\n",
            "Epoch 675, Generator Loss: 2.1725106239318848, Discriminator Loss: 0.8931668996810913\n",
            "Epoch 676, Generator Loss: 1.8576431274414062, Discriminator Loss: 0.8361632823944092\n",
            "Epoch 677, Generator Loss: 3.6450464725494385, Discriminator Loss: 0.7038298845291138\n",
            "Epoch 678, Generator Loss: 1.394205093383789, Discriminator Loss: 1.017171025276184\n",
            "Epoch 679, Generator Loss: 3.2760820388793945, Discriminator Loss: 1.0752449035644531\n",
            "Epoch 680, Generator Loss: 4.5325212478637695, Discriminator Loss: 0.9190541505813599\n",
            "Epoch 681, Generator Loss: 3.4229116439819336, Discriminator Loss: 0.8348691463470459\n",
            "Epoch 682, Generator Loss: 3.2587549686431885, Discriminator Loss: 1.1082249879837036\n",
            "Epoch 683, Generator Loss: 2.8751959800720215, Discriminator Loss: 0.6831002235412598\n",
            "Epoch 684, Generator Loss: 2.3499741554260254, Discriminator Loss: 0.9170560836791992\n",
            "Epoch 685, Generator Loss: 2.418619394302368, Discriminator Loss: 0.8380783796310425\n",
            "Epoch 686, Generator Loss: 2.0977582931518555, Discriminator Loss: 0.5203879475593567\n",
            "Epoch 687, Generator Loss: 1.4858946800231934, Discriminator Loss: 1.020094871520996\n",
            "Epoch 688, Generator Loss: 1.4397715330123901, Discriminator Loss: 1.163122534751892\n",
            "Epoch 689, Generator Loss: 1.5862170457839966, Discriminator Loss: 0.9541831612586975\n",
            "Epoch 690, Generator Loss: 2.176248073577881, Discriminator Loss: 0.7060917615890503\n",
            "Epoch 691, Generator Loss: 2.81009578704834, Discriminator Loss: 0.91898512840271\n",
            "Epoch 692, Generator Loss: 1.8285365104675293, Discriminator Loss: 0.904353141784668\n",
            "Epoch 693, Generator Loss: 3.627964496612549, Discriminator Loss: 1.4371715784072876\n",
            "Epoch 694, Generator Loss: 3.5605592727661133, Discriminator Loss: 0.7328665256500244\n",
            "Epoch 695, Generator Loss: 1.3949402570724487, Discriminator Loss: 1.016108751296997\n",
            "Epoch 696, Generator Loss: 1.428852915763855, Discriminator Loss: 0.9116193056106567\n",
            "Epoch 697, Generator Loss: 0.656511664390564, Discriminator Loss: 1.6229928731918335\n",
            "Epoch 698, Generator Loss: 1.7527796030044556, Discriminator Loss: 0.6582773923873901\n",
            "Epoch 699, Generator Loss: 3.76393723487854, Discriminator Loss: 0.6704325675964355\n",
            "Epoch 700, Generator Loss: 3.509124994277954, Discriminator Loss: 1.1400948762893677\n"
          ]
        }
      ],
      "source": [
        "# Define the training loop\n",
        "train(dataset, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D7Sz86UpP6v",
        "outputId": "1e9af18a-a32c-41c6-a697-fc2244beab4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "generator_loaded = load_model('/content/drive/My Drive/generator_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aU0nIcMin14i"
      },
      "outputs": [],
      "source": [
        "# Generate 100 synthetic images using the trained generator\n",
        "num_images = 13\n",
        "latent_space_samples = tf.random.normal([num_images, LATENT_DIM])\n",
        "generated_images = generator(latent_space_samples, training=False)\n",
        "\n",
        "# Rescale the generated images to 0-255 range\n",
        "generated_images = (generated_images * 127.5) + 127.5\n",
        "generated_images = generated_images.numpy().astype(np.uint8)\n",
        "\n",
        "# Save the generated images to disk\n",
        "output_dir = '/content/drive/My Drive/synthetic_images/lymph'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "for i in range(num_images):\n",
        "    filename = os.path.join(output_dir, f'last13_{i+1}.jpg')\n",
        "    img = Image.fromarray(generated_images[i])\n",
        "    img.save(filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHpyN5RfgiAD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}